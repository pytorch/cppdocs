:github_url: https://github.com/pytorch/pytorch


.. _file_torch_library.h:

File library.h
==============

|exhale_lsh| :ref:`Parent directory <dir_torch>` (``torch``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. contents:: Page Contents
   :local:
   :backlinks: none

Definition (``torch/library.h``)
--------------------------------


.. toctree::
   :maxdepth: 1

   program_listing_file_torch_library.h.rst



Detailed Description
--------------------

This header provides an API for extending PyTorch's core library of operators with user defined operators and data types. This API can be used in a few ways:



- You can define new custom operators and classes with :ref:`exhale_define_library_8h_1a0bd5fb09d25dfb58e750d712fc5afb84`, making them available for use in both eager Python as well as in TorchScript. This API is modeled off of pybind11's ``PYBIND11_MODULE`` macro, as the provided functionality is similar (pybind11 lets you bind C++ to Python only; ``torch/library.h`` lets you bind C++ simultaneously to Python and TorchScript).

- You can override existing operators with :ref:`exhale_define_library_8h_1a800b28569c0f7d0d9732bf8b6342d9f3`, providing a new implementation for these operators for a custom backend (e.g., XLA). When you pass operators with tensors of your custom backend, your overridden implementations will be called instead of the standard implementations.

- You can use both capabilities at the same time, allowing you to write custom operators that register CPU/CUDA/Autograd implementations without having to write the boilerplate conditionals yourself.



For a tutorial style introduction to the library API, check out the Extending TorchScript with Custom C++ Operators tutorial.

//Definealibrarywhoseoperatorsliveinthenamespace'myops'.
//Youmustdefinealloftheoperatorsforthislibraryin
//thisnamespace.
TORCH_LIBRARY(myops,m){
//Defineaoperatorwithexactlyoneimplementationforallbackends.
m.def("add(Tensorself,Tensorother)->Tensor",&add_impl);

//Defineaschemaforanoperator,butprovidenoimplementation
//(usethissyntaxifyouwanttousethedispatcher)
m.def("mul(Tensorself,Tensorother)->Tensor");

//Provideanimplementationforadefinedoperator(youcan
//providemultiple;oneperbackend).Thedispatchertakescareof
//callingthecorrectimplementationdependingonifwegetaCPU
//tensororaCUDAtensor
m.impl("mul",torch::kCPU,&mul_cpu_impl);
m.impl("mul",torch::kCUDA,&mul_cuda_impl);
}

//Defineimplementationsforoperatorsforanon-standardbackend,
//e.g.,XLA(validvaluesareentriesofDispatchKey).Thiscan
//beusedtodefineoperatorsinadifferentfilethantheinitial
//TORCH_LIBRARYdefinition(e.g.,ifitisinanexternallibrary)
TORCH_LIBRARY_IMPL(myops,XLA,m){
m.impl("mul",&mul_xla_impl);
}





Includes
--------


- ``ATen/core/enum_tag.h``

- ``ATen/core/op_registration/infer_schema.h``

- ``ATen/core/op_registration/op_allowlist.h``

- ``ATen/core/op_registration/op_registration.h``

- ``c10/core/DispatchKey.h``

- ``torch/csrc/jit/frontend/function_schema_parser.h``

- ``torch/custom_class.h`` (:ref:`file_torch_custom_class.h`)



Included By
-----------


- :ref:`file_torch_custom_class.h`

- :ref:`file_torch_csrc_api_include_torch_types.h`




Namespaces
----------


- :ref:`namespace_torch`

- :ref:`namespace_torch__detail`


Classes
-------


- :ref:`exhale_class_classtorch_1_1class__`

- :ref:`exhale_class_classtorch_1_1_cpp_function`

- :ref:`exhale_class_classtorch_1_1detail_1_1_class_not_selected`

- :ref:`exhale_class_classtorch_1_1detail_1_1_selective_str`

- :ref:`exhale_class_classtorch_1_1detail_1_1_torch_library_init`

- :ref:`exhale_class_classtorch_1_1_library`


Functions
---------


- :ref:`exhale_function_namespacetorch_1_1detail_1a3f2bbd0ea529200d36fa1e866e823be9`

- :ref:`exhale_function_namespacetorch_1_1detail_1a5348dac760b9c88da5bd2f69dfdab83d`

- :ref:`exhale_function_namespacetorch_1_1detail_1a342444776cc0b8161e88ac158d847293`

- :ref:`exhale_function_group__torch-dispatch-overloads_1ga91120ca3079a024775f01ea37e7fcbd8`

- :ref:`exhale_function_group__torch-dispatch-overloads_1ga2037ceb48b4bcf8a09f3f2def4e1b545`

- :ref:`exhale_function_group__torch-schema-overloads_1ga4f19c794ea92aec0028da4c382ef409d`

- :ref:`exhale_function_group__torch-schema-overloads_1ga8113206fb9a640d3fc22ca2c49a1b3d9`

- :ref:`exhale_function_group__torch-schema-overloads_1ga201401ec7c0cb2145698d01f6a7ed10e`


Defines
-------


- :ref:`exhale_define_library_8h_1a7c50f3ba858b115d20cda8ca5e84e1db`

- :ref:`exhale_define_library_8h_1ad734202578236c555136bff6337becbd`

- :ref:`exhale_define_library_8h_1af7172260a7c49ffb402486261122bfd6`

- :ref:`exhale_define_library_8h_1aa07933001180e84f94ba264671a856ee`

- :ref:`exhale_define_library_8h_1a0bd5fb09d25dfb58e750d712fc5afb84`

- :ref:`exhale_define_library_8h_1a2eabc7781e58671237d9d0d282ee1814`

- :ref:`exhale_define_library_8h_1a800b28569c0f7d0d9732bf8b6342d9f3`

- :ref:`exhale_define_library_8h_1a2e48a234b185f3c2fd80a77fbee8d98d`

- :ref:`exhale_define_library_8h_1a52347fd3fabb0d7989a84aa265ff9bef`

- :ref:`exhale_define_library_8h_1ae2e6d410e2ce4a8d9aff6e212e802d08`

