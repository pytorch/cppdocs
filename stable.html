
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Torch Stable API &#8212; PyTorch main documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=047068a3" />
    <link rel="stylesheet" type="text/css" href="_static/collapsible-lists/css/tree_view.css?v=a885cde7" />
    <link rel="stylesheet" type="text/css" href="_static/cpp_theme.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=a8da1a53"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/collapsible-lists/js/CollapsibleLists.compressed.js?v=73120307"></script>
    <script src="_static/collapsible-lists/js/apply-collapsible-lists.js?v=660e4f45"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'stable';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Library API" href="api/library_root.html" />
    <link rel="prev" title="The C++ Frontend" href="frontend.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->


<link rel="stylesheet" type="text/css" href="_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'main');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->

<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>

<body data-feedback-url="https://github.com/pytorch/pytorch" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                <span>Learn</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started/locally">
                  <span class=dropdown-title>Get Started</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
                  <span class="dropdown-title">Webinars</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Community</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
                  <span class="dropdown-title">Join the Ecosystem</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
                  <span class="dropdown-title">Community Hub</span>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
                  <span class="dropdown-title">Forums</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
                  <span class="dropdown-title">Contributor Awards</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
                  <span class="dropdown-title">Community Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
                  <span class="dropdown-title">PyTorch Ambassadors</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Projects</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
                  <span class="dropdown-title">vLLM</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
                  <span class="dropdown-title">DeepSpeed</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
                  <span class="dropdown-title">Host Your Project</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/ray/">
                  <span class="dropdown-title">RAY</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span> Docs</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/domains">
                  <span class="dropdown-title">Domains</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Blogs & News</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">Blog</span>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/announcements">
                  <span class="dropdown-title">Announcements</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
                  <span class="dropdown-title">Case Studies</span>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                </a>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>About</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/members">
                  <span class="dropdown-title">Members</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact">
                  <span class="dropdown-title">Contact</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/wp-content/uploads/2025/09/pytorch_brand_guide_091925a.pdf">
                  <span class="dropdown-title">Brand Guidelines</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown main-menu-button">
              <a href="https://pytorch.org/join" data-cta="join">
                JOIN
              </a>
            </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>Learn</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/get-started/locally">Get Started</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials">Tutorials</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
           </li>
           <li>
            <a href="https://pytorch.org/webinars/">Webinars</a>
          </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a>Community</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Landscape</a>
          </li>
          <li>
             <a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
           </li>
           <li>
             <a href="https://pytorch.org/community-hub/">Community Hub</a>
           </li>
           <li>
             <a href="https://discuss.pytorch.org/">Forums</a>
           </li>
           <li>
             <a href="https://pytorch.org/resources">Developer Resources</a>
           </li>
           <li>
             <a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
           </li>
           <li>
            <a href="https://pytorch.org/community-events/">Community Events</a>
          </li>
          <li>
            <a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
          </li>
       </ul>

         <li class="resources-mobile-menu-title">
           <a>Projects</a>
         </li>

         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
           </li>

           <li>
             <a href="https://pytorch.org/projects/vllm/">vLLM</a>
           </li>
           <li>
            <a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
          </li>
          <li>
             <a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Docs</a>
         </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/stable/index.html">PyTorch</a>
          </li>

          <li>
            <a href="https://pytorch.org/domains">Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>
          <li>
            <a href="https://pytorch.org/announcements">Announcements</a>
          </li>

          <li>
            <a href="https://pytorch.org/case-studies/">Case Studies</a>
          </li>
          <li>
            <a href="https://pytorch.org/events">Events</a>
          </li>
          <li>
             <a href="https://pytorch.org/newsletter">Newsletter</a>
           </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="https://pytorch.org/members">Members</a>
          </li>
          <li>
            <a href="https://pytorch.org/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="https://pytorch.org/tac">Technical Advisory Council</a>
         </li>
         <li>
             <a href="https://pytorch.org/credits">Cloud Credit Program</a>
          </li>
          <li>
             <a href="https://pytorch.org/staff">Staff</a>
          </li>
          <li>
             <a href="https://pytorch.org/contact">Contact</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="index.html" class="version">main</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="installing.html">
    Installing C++ Distributions of PyTorch
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="frontend.html">
    The C++ Frontend
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="#">
    Torch Stable API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="api/library_root.html">
    Library API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="notes/faq.html">
    FAQ
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="notes/inference_mode.html">
    Inference Mode
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="notes/maybe_owned.html">
    MaybeOwned<Tensor>
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="notes/tensor_basics.html">
    Tensor Basics
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="notes/tensor_creation.html">
    Tensor Creation API
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="notes/tensor_cuda_stream.html">
    Tensor CUDA Stream API
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="notes/tensor_indexing.html">
    Tensor Indexing API
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="notes/versioning.html">
    Library Versioning
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="PyTorch Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyTorch Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="installing.html">
    Installing C++ Distributions of PyTorch
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="frontend.html">
    The C++ Frontend
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="#">
    Torch Stable API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="api/library_root.html">
    Library API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="notes/faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="notes/inference_mode.html">
    Inference Mode
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="notes/maybe_owned.html">
    MaybeOwned<Tensor>
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="notes/tensor_basics.html">
    Tensor Basics
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="notes/tensor_creation.html">
    Tensor Creation API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="notes/tensor_cuda_stream.html">
    Tensor CUDA Stream API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="notes/tensor_indexing.html">
    Tensor Indexing API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="notes/versioning.html">
    Library Versioning
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="PyTorch Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyTorch Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"></div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page">Torch Stable API</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="Torch Stable API">
        <meta itemprop="position" content="1">
      </div>
    </div>

    
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="torch-stable-api">
<h1>Torch Stable API<a class="headerlink" href="#torch-stable-api" title="Link to this heading">#</a></h1>
<p>The PyTorch Stable C++ API provides a convenient high level interface to call
ABI-stable tensor operations and other utilities commonly used in custom operators.
These functions are designed to maintain binary compatibility across PyTorch versions,
making them suitable for use in ahead-of-time compiled code.</p>
<p>For more information on the stable ABI, see the
<a class="reference external" href="https://docs.pytorch.org/docs/stable/notes/libtorch_stable_abi.html">Stable ABI notes</a>.</p>
<section id="library-registration-macros">
<h2>Library Registration Macros<a class="headerlink" href="#library-registration-macros" title="Link to this heading">#</a></h2>
<p>These macros provide stable ABI equivalents of the standard PyTorch operator
registration macros (<code class="docutils literal notranslate"><span class="pre">TORCH_LIBRARY</span></code>, <code class="docutils literal notranslate"><span class="pre">TORCH_LIBRARY_IMPL</span></code>, etc.).
Use these when building custom operators that need to maintain binary
compatibility across PyTorch versions.</p>
<section id="stable-torch-library-ns-m">
<h3><code class="docutils literal notranslate"><span class="pre">STABLE_TORCH_LIBRARY(ns,</span> <span class="pre">m)</span></code><a class="headerlink" href="#stable-torch-library-ns-m" title="Link to this heading">#</a></h3>
<p>Defines a library of operators in a namespace using the stable ABI.</p>
<p>This is the stable ABI equivalent of <a class="reference internal" href="api/define_library_8h_1a0bd5fb09d25dfb58e750d712fc5afb84.html#c.TORCH_LIBRARY" title="TORCH_LIBRARY"><code class="xref c c-macro docutils literal notranslate"><span class="pre">TORCH_LIBRARY</span></code></a>.
Use this macro to define operator schemas that will maintain
binary compatibility across PyTorch versions. Only one <code class="docutils literal notranslate"><span class="pre">STABLE_TORCH_LIBRARY</span></code>
block can exist per namespace; use <code class="docutils literal notranslate"><span class="pre">STABLE_TORCH_LIBRARY_FRAGMENT</span></code> for
additional definitions in the same namespace from different translation units.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ns</span></code> - The namespace in which to define operators (e.g., <code class="docutils literal notranslate"><span class="pre">mylib</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">m</span></code> - The name of the StableLibrary variable available in the block.</p></li>
</ul>
<p><strong>Example:</strong></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">STABLE_TORCH_LIBRARY</span><span class="p">(</span><span class="n">mylib</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">m</span><span class="p">.</span><span class="n">def</span><span class="p">(</span><span class="s">&quot;my_op(Tensor input, int size) -&gt; Tensor&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="n">m</span><span class="p">.</span><span class="n">def</span><span class="p">(</span><span class="s">&quot;another_op(Tensor a, Tensor b) -&gt; Tensor&quot;</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Minimum compatible version: PyTorch 2.9.</p>
</section>
<section id="stable-torch-library-impl-ns-k-m">
<h3><code class="docutils literal notranslate"><span class="pre">STABLE_TORCH_LIBRARY_IMPL(ns,</span> <span class="pre">k,</span> <span class="pre">m)</span></code><a class="headerlink" href="#stable-torch-library-impl-ns-k-m" title="Link to this heading">#</a></h3>
<p>Registers operator implementations for a specific dispatch key using the stable ABI.</p>
<p>This is the stable ABI equivalent of <code class="docutils literal notranslate"><span class="pre">TORCH_LIBRARY_IMPL</span></code>. Use this macro
to provide implementations of operators for a specific dispatch key (e.g.,
CPU, CUDA) while maintaining binary compatibility across PyTorch versions.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All kernel functions registered with this macro must be boxed using
the <code class="docutils literal notranslate"><span class="pre">TORCH_BOX</span></code> macro.</p>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ns</span></code> - The namespace in which the operators are defined.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">k</span></code> - The dispatch key (e.g., <code class="docutils literal notranslate"><span class="pre">CPU</span></code>, <code class="docutils literal notranslate"><span class="pre">CUDA</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">m</span></code> - The name of the StableLibrary variable available in the block.</p></li>
</ul>
<p><strong>Example:</strong></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">STABLE_TORCH_LIBRARY_IMPL</span><span class="p">(</span><span class="n">mylib</span><span class="p">,</span><span class="w"> </span><span class="n">CPU</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">m</span><span class="p">.</span><span class="n">impl</span><span class="p">(</span><span class="s">&quot;my_op&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">TORCH_BOX</span><span class="p">(</span><span class="o">&amp;</span><span class="n">my_cpu_kernel</span><span class="p">));</span>
<span class="p">}</span>

<span class="n">STABLE_TORCH_LIBRARY_IMPL</span><span class="p">(</span><span class="n">mylib</span><span class="p">,</span><span class="w"> </span><span class="n">CUDA</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">m</span><span class="p">.</span><span class="n">impl</span><span class="p">(</span><span class="s">&quot;my_op&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">TORCH_BOX</span><span class="p">(</span><span class="o">&amp;</span><span class="n">my_cuda_kernel</span><span class="p">));</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Minimum compatible version: PyTorch 2.9.</p>
</section>
<section id="stable-torch-library-fragment-ns-m">
<h3><code class="docutils literal notranslate"><span class="pre">STABLE_TORCH_LIBRARY_FRAGMENT(ns,</span> <span class="pre">m)</span></code><a class="headerlink" href="#stable-torch-library-fragment-ns-m" title="Link to this heading">#</a></h3>
<p>Extends operator definitions in an existing namespace using the stable ABI.</p>
<p>This is the stable ABI equivalent of <code class="docutils literal notranslate"><span class="pre">TORCH_LIBRARY_FRAGMENT</span></code>. Use this macro
to add additional operator definitions to a namespace that was already
created with <code class="docutils literal notranslate"><span class="pre">STABLE_TORCH_LIBRARY</span></code>.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ns</span></code> - The namespace to extend.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">m</span></code> - The name of the StableLibrary variable available in the block.</p></li>
</ul>
<p>Minimum compatible version: PyTorch 2.9.</p>
</section>
<section id="torch-box-func">
<h3><code class="docutils literal notranslate"><span class="pre">TORCH_BOX(&amp;func)</span></code><a class="headerlink" href="#torch-box-func" title="Link to this heading">#</a></h3>
<p>Wraps a function to conform to the stable boxed kernel calling convention.</p>
<p>This macro takes an unboxed kernel function pointer and generates a boxed wrapper
that can be registered with the stable library API.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">func</span></code> - The unboxed kernel function to wrap.</p></li>
</ul>
<p><strong>Example:</strong></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Tensor</span><span class="w"> </span><span class="nf">my_kernel</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">input</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">input</span><span class="p">.</span><span class="n">reshape</span><span class="p">({</span><span class="n">size</span><span class="p">});</span>
<span class="p">}</span>

<span class="n">STABLE_TORCH_LIBRARY_IMPL</span><span class="p">(</span><span class="n">my_namespace</span><span class="p">,</span><span class="w"> </span><span class="n">CPU</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">m</span><span class="p">.</span><span class="n">impl</span><span class="p">(</span><span class="s">&quot;my_op&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">TORCH_BOX</span><span class="p">(</span><span class="o">&amp;</span><span class="n">my_kernel</span><span class="p">));</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Minimum compatible version: PyTorch 2.9.</p>
</section>
</section>
<section id="tensor-class">
<h2>Tensor Class<a class="headerlink" href="#tensor-class" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">torch::stable::Tensor</span></code> class offers a user-friendly C++ interface similar
to <code class="docutils literal notranslate"><span class="pre">torch::Tensor</span></code> while maintaining binary compatibility across PyTorch versions.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenclass: Cannot find class “torch::stable::Tensor” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
</section>
<section id="device-class">
<h2>Device Class<a class="headerlink" href="#device-class" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">torch::stable::Device</span></code> class provides a user-friendly C++ interface similar
to <code class="docutils literal notranslate"><span class="pre">c10::Device</span></code> while maintaining binary compatibility across PyTorch versions.
It represents a compute device (CPU, CUDA, etc.) with an optional device index.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenclass: Cannot find class “torch::stable::Device” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
</section>
<section id="deviceguard-class">
<h2>DeviceGuard Class<a class="headerlink" href="#deviceguard-class" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">torch::stable::accelerator::DeviceGuard</span></code> provides a user-friendly C++
interface similar to <code class="docutils literal notranslate"><span class="pre">c10::DeviceGuard</span></code> while maintaining binary compatibility
across PyTorch versions.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenclass: Cannot find class “torch::stable::accelerator::DeviceGuard” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::accelerator::getCurrentDeviceIndex” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
</section>
<section id="stream-utilities">
<h2>Stream Utilities<a class="headerlink" href="#stream-utilities" title="Link to this heading">#</a></h2>
<p>For CUDA stream access, we currently recommend the ABI stable C shim API. This
will be improved in a future release with a more ergonomic wrapper.</p>
<section id="getting-the-current-cuda-stream">
<h3>Getting the Current CUDA Stream<a class="headerlink" href="#getting-the-current-cuda-stream" title="Link to this heading">#</a></h3>
<p>To obtain the current <code class="docutils literal notranslate"><span class="pre">cudaStream_t</span></code> for use in CUDA kernels:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/csrc/inductor/aoti_torch/c/shim.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/headeronly/util/shim_utils.h&gt;</span>

<span class="c1">// For now, we rely on the ABI stable C shim API to get the current CUDA stream.</span>
<span class="c1">// This will be improved in a future release.</span>
<span class="c1">// When using a C shim API, we need to use TORCH_ERROR_CODE_CHECK to</span>
<span class="c1">// check the error code and throw an appropriate runtime_error otherwise.</span>
<span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">stream_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="n">TORCH_ERROR_CODE_CHECK</span><span class="p">(</span>
<span class="w">    </span><span class="n">aoti_torch_get_current_cuda_stream</span><span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="n">get_device_index</span><span class="p">(),</span><span class="w"> </span><span class="o">&amp;</span><span class="n">stream_ptr</span><span class="p">));</span>
<span class="n">cudaStream_t</span><span class="w"> </span><span class="n">stream</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="n">cudaStream_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">stream_ptr</span><span class="p">);</span>

<span class="c1">// Now you can use &#39;stream&#39; in your CUDA kernel launches</span>
<span class="n">my_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threads</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">args</span><span class="p">...);</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">TORCH_ERROR_CODE_CHECK</span></code> macro is required when using C shim APIs
to properly check error codes and throw appropriate exceptions.</p>
</div>
</section>
</section>
<section id="cuda-error-checking-macros">
<h2>CUDA Error Checking Macros<a class="headerlink" href="#cuda-error-checking-macros" title="Link to this heading">#</a></h2>
<p>These macros provide stable ABI equivalents for CUDA error checking.
They wrap CUDA API calls and kernel launches, providing detailed error
messages using PyTorch’s error formatting.</p>
<section id="std-cuda-check-expr">
<h3><code class="docutils literal notranslate"><span class="pre">STD_CUDA_CHECK(EXPR)</span></code><a class="headerlink" href="#std-cuda-check-expr" title="Link to this heading">#</a></h3>
<p>Checks the result of a CUDA API call and throws an exception on error.
Users of this macro are expected to include <code class="docutils literal notranslate"><span class="pre">cuda_runtime.h</span></code>.</p>
<p><strong>Example:</strong></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">STD_CUDA_CHECK</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ptr</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">));</span>
<span class="n">STD_CUDA_CHECK</span><span class="p">(</span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">));</span>
</pre></div>
</div>
<p>Minimum compatible version: PyTorch 2.10.</p>
</section>
<section id="std-cuda-kernel-launch-check">
<h3><code class="docutils literal notranslate"><span class="pre">STD_CUDA_KERNEL_LAUNCH_CHECK()</span></code><a class="headerlink" href="#std-cuda-kernel-launch-check" title="Link to this heading">#</a></h3>
<p>Checks for errors from the most recent CUDA kernel launch. Equivalent to
<code class="docutils literal notranslate"><span class="pre">STD_CUDA_CHECK(cudaGetLastError())</span></code>.</p>
<p><strong>Example:</strong></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">my_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threads</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">args</span><span class="p">...);</span>
<span class="n">STD_CUDA_KERNEL_LAUNCH_CHECK</span><span class="p">();</span>
</pre></div>
</div>
<p>Minimum compatible version: PyTorch 2.10.</p>
</section>
</section>
<section id="header-only-utilities">
<h2>Header-Only Utilities<a class="headerlink" href="#header-only-utilities" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">torch::headeronly</span></code> namespace provides header-only versions of common
PyTorch types and utilities. These can be used without linking against libtorch,
making them ideal for maintaining binary compatibility across PyTorch versions.</p>
<section id="error-checking">
<h3>Error Checking<a class="headerlink" href="#error-checking" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">STD_TORCH_CHECK</span></code> is a header-only macro for runtime assertions:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/headeronly/util/Exception.h&gt;</span>

<span class="n">STD_TORCH_CHECK</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Error message with &quot;</span><span class="p">,</span><span class="w"> </span><span class="n">variable</span><span class="p">,</span><span class="w"> </span><span class="s">&quot; interpolation&quot;</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="core-types">
<h3>Core Types<a class="headerlink" href="#core-types" title="Link to this heading">#</a></h3>
<p>The following <code class="docutils literal notranslate"><span class="pre">c10::</span></code> types are available as header-only versions under
<code class="docutils literal notranslate"><span class="pre">torch::headeronly::</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">torch::headeronly::ScalarType</span></code> - Tensor data types (Float, Double, Int, etc.)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch::headeronly::DeviceType</span></code> - Device types (CPU, CUDA, etc.)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch::headeronly::MemoryFormat</span></code> - Memory layout formats (Contiguous, ChannelsLast, etc.)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch::headeronly::Layout</span></code> - Tensor layouts (Strided, Sparse, etc.)</p></li>
</ul>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/headeronly/core/ScalarType.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/headeronly/core/DeviceType.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/headeronly/core/MemoryFormat.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/headeronly/core/Layout.h&gt;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">dtype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">headeronly</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">::</span><span class="n">Float</span><span class="p">;</span>
<span class="k">auto</span><span class="w"> </span><span class="n">device_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">headeronly</span><span class="o">::</span><span class="n">DeviceType</span><span class="o">::</span><span class="n">CUDA</span><span class="p">;</span>
<span class="k">auto</span><span class="w"> </span><span class="n">memory_format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">headeronly</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">::</span><span class="n">Contiguous</span><span class="p">;</span>
<span class="k">auto</span><span class="w"> </span><span class="n">layout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">headeronly</span><span class="o">::</span><span class="n">Layout</span><span class="o">::</span><span class="n">Strided</span><span class="p">;</span>
</pre></div>
</div>
</section>
<section id="tensoraccessor">
<h3>TensorAccessor<a class="headerlink" href="#tensoraccessor" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">TensorAccessor</span></code> provides efficient, bounds-checked access to tensor data.
You can construct one from a stable tensor’s data pointer, sizes, and strides:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/headeronly/core/TensorAccessor.h&gt;</span>

<span class="c1">// Create a TensorAccessor for a 2D float tensor</span>
<span class="k">auto</span><span class="w"> </span><span class="n">sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">sizes</span><span class="p">();</span>
<span class="k">auto</span><span class="w"> </span><span class="n">strides</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">strides</span><span class="p">();</span>
<span class="n">torch</span><span class="o">::</span><span class="n">headeronly</span><span class="o">::</span><span class="n">TensorAccessor</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">&gt;</span><span class="w"> </span><span class="n">accessor</span><span class="p">(</span>
<span class="w">    </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="n">mutable_data_ptr</span><span class="p">()),</span>
<span class="w">    </span><span class="n">sizes</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span>
<span class="w">    </span><span class="n">strides</span><span class="p">.</span><span class="n">data</span><span class="p">());</span>

<span class="c1">// Access elements</span>
<span class="kt">float</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">accessor</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
</pre></div>
</div>
</section>
<section id="dispatch-macros">
<h3>Dispatch Macros<a class="headerlink" href="#dispatch-macros" title="Link to this heading">#</a></h3>
<p>Header-only dispatch macros (THO = Torch Header Only) are available for
dtype and device dispatching:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/headeronly/core/Dispatch.h&gt;</span>

<span class="n">THO_DISPATCH_FLOATING_TYPES</span><span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="n">scalar_type</span><span class="p">(),</span><span class="w"> </span><span class="s">&quot;my_kernel&quot;</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="o">&amp;</span><span class="p">]</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// scalar_t is the resolved type</span>
<span class="w">    </span><span class="k">auto</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tensor</span><span class="p">.</span><span class="n">data_ptr</span><span class="o">&lt;</span><span class="n">scalar_t</span><span class="o">&gt;</span><span class="p">();</span>
<span class="p">});</span>
</pre></div>
</div>
</section>
<section id="full-api-list">
<h3>Full API List<a class="headerlink" href="#full-api-list" title="Link to this heading">#</a></h3>
<p>For the complete list of header-only APIs, see <code class="docutils literal notranslate"><span class="pre">torch/header_only_apis.txt</span></code>
in the PyTorch source tree.</p>
</section>
</section>
<section id="stable-operators">
<h2>Stable Operators<a class="headerlink" href="#stable-operators" title="Link to this heading">#</a></h2>
<section id="tensor-creation">
<h3>Tensor Creation<a class="headerlink" href="#tensor-creation" title="Link to this heading">#</a></h3>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::empty” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::empty_like” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::new_empty” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::new_zeros” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::full” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::from_blob” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
</section>
<section id="tensor-manipulation">
<h3>Tensor Manipulation<a class="headerlink" href="#tensor-manipulation" title="Link to this heading">#</a></h3>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::clone” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::contiguous” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::reshape” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::view” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::flatten” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::squeeze” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::unsqueeze” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::transpose” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::select” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::narrow” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::pad” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
</section>
<section id="device-and-type-conversion">
<h3>Device and Type Conversion<a class="headerlink" href="#device-and-type-conversion" title="Link to this heading">#</a></h3>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::to” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::to” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::fill_” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::zero_” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::copy_” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::matmul” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::amax” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::amax” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::sum” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::sum_out” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::subtract” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::parallel_for” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::get_num_threads” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
</section>
<section id="parallelization-utilities">
<h3>Parallelization Utilities<a class="headerlink" href="#parallelization-utilities" title="Link to this heading">#</a></h3>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::parallel_for” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>doxygenfunction: Cannot find function “torch::stable::get_num_threads” in doxygen xml output for project “PyTorch” from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml</p>
</div>
</section>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="frontend.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">The C++ Frontend</p>
      </div>
    </a>
    <a class="right-next"
       href="api/library_root.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Library API</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="frontend.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">The C++ Frontend</p>
      </div>
    </a>
    <a class="right-next"
       href="api/library_root.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Library API</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#library-registration-macros">Library Registration Macros</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stable-torch-library-ns-m"><code class="docutils literal notranslate"><span class="pre">STABLE_TORCH_LIBRARY(ns,</span> <span class="pre">m)</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stable-torch-library-impl-ns-k-m"><code class="docutils literal notranslate"><span class="pre">STABLE_TORCH_LIBRARY_IMPL(ns,</span> <span class="pre">k,</span> <span class="pre">m)</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stable-torch-library-fragment-ns-m"><code class="docutils literal notranslate"><span class="pre">STABLE_TORCH_LIBRARY_FRAGMENT(ns,</span> <span class="pre">m)</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torch-box-func"><code class="docutils literal notranslate"><span class="pre">TORCH_BOX(&amp;func)</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensor-class">Tensor Class</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#device-class">Device Class</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deviceguard-class">DeviceGuard Class</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stream-utilities">Stream Utilities</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-the-current-cuda-stream">Getting the Current CUDA Stream</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cuda-error-checking-macros">CUDA Error Checking Macros</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#std-cuda-check-expr"><code class="docutils literal notranslate"><span class="pre">STD_CUDA_CHECK(EXPR)</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#std-cuda-kernel-launch-check"><code class="docutils literal notranslate"><span class="pre">STD_CUDA_KERNEL_LAUNCH_CHECK()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#header-only-utilities">Header-Only Utilities</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#error-checking">Error Checking</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#core-types">Core Types</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tensoraccessor">TensorAccessor</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dispatch-macros">Dispatch Macros</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#full-api-list">Full API List</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stable-operators">Stable Operators</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tensor-creation">Tensor Creation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tensor-manipulation">Tensor Manipulation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#device-and-type-conversion">Device and Type Conversion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parallelization-utilities">Parallelization Utilities</a></li>
</ul>
</li>
</ul>
  </nav></div>
    
       <div class="sidebar-secondary-item">
    <div class="tocsection sourcelink">
      <a href="_sources/stable.rst.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
      </a>
    </div>
</div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  

<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
      </div>

      <div class="col-md-4">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>




<footer class="site-footer">

  <div class="container footer-container">

    <div class="newsletter" id="newsletter">

      <p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>


      <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
      <script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>


      <p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a
          href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>

    </div>

    <div class="lf-grid">
      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook">
              <path fill="currentColor"
                d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" />
            </svg>
          </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X">
              <path fill="currentColor"
                d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" />
            </svg>
          </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube">
              <path fill="currentColor"
                d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" />
            </svg>
          </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn">
              <rect width="512" height="512" rx="0" fill="currentColor" />
              <circle fill="#000" cx="142" cy="138" r="37" />
              <path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198" />
              <path fill="#000"
                d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" />
            </svg>
          </a></li>
        <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack">
              <path fill="currentColor"
                d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z">
              </path>
            </svg>
          </a></li>
        <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat">
              <path fill="currentColor"
                d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z">
              </path>
              <path fill="currentColor"
                d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z">
              </path>
            </svg>
          </a></li>
      </ul>
    </div>
    
    <div class="privacy-policy">
      <div class="copyright">
      
        <p>
          &copy; PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a
            href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a
            href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright PyTorch Contributors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Torch Stable API",
       "headline": "Torch Stable API",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/stable.html",
       "articleBody": "Torch Stable API# The PyTorch Stable C++ API provides a convenient high level interface to call ABI-stable tensor operations and other utilities commonly used in custom operators. These functions are designed to maintain binary compatibility across PyTorch versions, making them suitable for use in ahead-of-time compiled code. For more information on the stable ABI, see the Stable ABI notes. Library Registration Macros# These macros provide stable ABI equivalents of the standard PyTorch operator registration macros (TORCH_LIBRARY, TORCH_LIBRARY_IMPL, etc.). Use these when building custom operators that need to maintain binary compatibility across PyTorch versions. STABLE_TORCH_LIBRARY(ns, m)# Defines a library of operators in a namespace using the stable ABI. This is the stable ABI equivalent of TORCH_LIBRARY. Use this macro to define operator schemas that will maintain binary compatibility across PyTorch versions. Only one STABLE_TORCH_LIBRARY block can exist per namespace; use STABLE_TORCH_LIBRARY_FRAGMENT for additional definitions in the same namespace from different translation units. Parameters: ns - The namespace in which to define operators (e.g., mylib). m - The name of the StableLibrary variable available in the block. Example: STABLE_TORCH_LIBRARY(mylib, m) { m.def(\"my_op(Tensor input, int size) -\u003e Tensor\"); m.def(\"another_op(Tensor a, Tensor b) -\u003e Tensor\"); } Minimum compatible version: PyTorch 2.9. STABLE_TORCH_LIBRARY_IMPL(ns, k, m)# Registers operator implementations for a specific dispatch key using the stable ABI. This is the stable ABI equivalent of TORCH_LIBRARY_IMPL. Use this macro to provide implementations of operators for a specific dispatch key (e.g., CPU, CUDA) while maintaining binary compatibility across PyTorch versions. Note All kernel functions registered with this macro must be boxed using the TORCH_BOX macro. Parameters: ns - The namespace in which the operators are defined. k - The dispatch key (e.g., CPU, CUDA). m - The name of the StableLibrary variable available in the block. Example: STABLE_TORCH_LIBRARY_IMPL(mylib, CPU, m) { m.impl(\"my_op\", TORCH_BOX(\u0026my_cpu_kernel)); } STABLE_TORCH_LIBRARY_IMPL(mylib, CUDA, m) { m.impl(\"my_op\", TORCH_BOX(\u0026my_cuda_kernel)); } Minimum compatible version: PyTorch 2.9. STABLE_TORCH_LIBRARY_FRAGMENT(ns, m)# Extends operator definitions in an existing namespace using the stable ABI. This is the stable ABI equivalent of TORCH_LIBRARY_FRAGMENT. Use this macro to add additional operator definitions to a namespace that was already created with STABLE_TORCH_LIBRARY. Parameters: ns - The namespace to extend. m - The name of the StableLibrary variable available in the block. Minimum compatible version: PyTorch 2.9. TORCH_BOX(\u0026func)# Wraps a function to conform to the stable boxed kernel calling convention. This macro takes an unboxed kernel function pointer and generates a boxed wrapper that can be registered with the stable library API. Parameters: func - The unboxed kernel function to wrap. Example: Tensor my_kernel(const Tensor\u0026 input, int64_t size) { return input.reshape({size}); } STABLE_TORCH_LIBRARY_IMPL(my_namespace, CPU, m) { m.impl(\"my_op\", TORCH_BOX(\u0026my_kernel)); } Minimum compatible version: PyTorch 2.9. Tensor Class# The torch::stable::Tensor class offers a user-friendly C++ interface similar to torch::Tensor while maintaining binary compatibility across PyTorch versions. Warning doxygenclass: Cannot find class \u201ctorch::stable::Tensor\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Device Class# The torch::stable::Device class provides a user-friendly C++ interface similar to c10::Device while maintaining binary compatibility across PyTorch versions. It represents a compute device (CPU, CUDA, etc.) with an optional device index. Warning doxygenclass: Cannot find class \u201ctorch::stable::Device\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml DeviceGuard Class# The torch::stable::accelerator::DeviceGuard provides a user-friendly C++ interface similar to c10::DeviceGuard while maintaining binary compatibility across PyTorch versions. Warning doxygenclass: Cannot find class \u201ctorch::stable::accelerator::DeviceGuard\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::accelerator::getCurrentDeviceIndex\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Stream Utilities# For CUDA stream access, we currently recommend the ABI stable C shim API. This will be improved in a future release with a more ergonomic wrapper. Getting the Current CUDA Stream# To obtain the current cudaStream_t for use in CUDA kernels: #include \u003ctorch/csrc/inductor/aoti_torch/c/shim.h\u003e #include \u003ctorch/headeronly/util/shim_utils.h\u003e // For now, we rely on the ABI stable C shim API to get the current CUDA stream. // This will be improved in a future release. // When using a C shim API, we need to use TORCH_ERROR_CODE_CHECK to // check the error code and throw an appropriate runtime_error otherwise. void* stream_ptr = nullptr; TORCH_ERROR_CODE_CHECK( aoti_torch_get_current_cuda_stream(tensor.get_device_index(), \u0026stream_ptr)); cudaStream_t stream = static_cast\u003ccudaStream_t\u003e(stream_ptr); // Now you can use \u0027stream\u0027 in your CUDA kernel launches my_kernel\u003c\u003c\u003cblocks, threads, 0, stream\u003e\u003e\u003e(args...); Note The TORCH_ERROR_CODE_CHECK macro is required when using C shim APIs to properly check error codes and throw appropriate exceptions. CUDA Error Checking Macros# These macros provide stable ABI equivalents for CUDA error checking. They wrap CUDA API calls and kernel launches, providing detailed error messages using PyTorch\u2019s error formatting. STD_CUDA_CHECK(EXPR)# Checks the result of a CUDA API call and throws an exception on error. Users of this macro are expected to include cuda_runtime.h. Example: STD_CUDA_CHECK(cudaMalloc(\u0026ptr, size)); STD_CUDA_CHECK(cudaMemcpy(dst, src, size, cudaMemcpyDeviceToHost)); Minimum compatible version: PyTorch 2.10. STD_CUDA_KERNEL_LAUNCH_CHECK()# Checks for errors from the most recent CUDA kernel launch. Equivalent to STD_CUDA_CHECK(cudaGetLastError()). Example: my_kernel\u003c\u003c\u003cblocks, threads, 0, stream\u003e\u003e\u003e(args...); STD_CUDA_KERNEL_LAUNCH_CHECK(); Minimum compatible version: PyTorch 2.10. Header-Only Utilities# The torch::headeronly namespace provides header-only versions of common PyTorch types and utilities. These can be used without linking against libtorch, making them ideal for maintaining binary compatibility across PyTorch versions. Error Checking# STD_TORCH_CHECK is a header-only macro for runtime assertions: #include \u003ctorch/headeronly/util/Exception.h\u003e STD_TORCH_CHECK(condition, \"Error message with \", variable, \" interpolation\"); Core Types# The following c10:: types are available as header-only versions under torch::headeronly::: torch::headeronly::ScalarType - Tensor data types (Float, Double, Int, etc.) torch::headeronly::DeviceType - Device types (CPU, CUDA, etc.) torch::headeronly::MemoryFormat - Memory layout formats (Contiguous, ChannelsLast, etc.) torch::headeronly::Layout - Tensor layouts (Strided, Sparse, etc.) #include \u003ctorch/headeronly/core/ScalarType.h\u003e #include \u003ctorch/headeronly/core/DeviceType.h\u003e #include \u003ctorch/headeronly/core/MemoryFormat.h\u003e #include \u003ctorch/headeronly/core/Layout.h\u003e auto dtype = torch::headeronly::ScalarType::Float; auto device_type = torch::headeronly::DeviceType::CUDA; auto memory_format = torch::headeronly::MemoryFormat::Contiguous; auto layout = torch::headeronly::Layout::Strided; TensorAccessor# TensorAccessor provides efficient, bounds-checked access to tensor data. You can construct one from a stable tensor\u2019s data pointer, sizes, and strides: #include \u003ctorch/headeronly/core/TensorAccessor.h\u003e // Create a TensorAccessor for a 2D float tensor auto sizes = tensor.sizes(); auto strides = tensor.strides(); torch::headeronly::TensorAccessor\u003cfloat, 2\u003e accessor( static_cast\u003cfloat*\u003e(tensor.mutable_data_ptr()), sizes.data(), strides.data()); // Access elements float value = accessor[i][j]; Dispatch Macros# Header-only dispatch macros (THO = Torch Header Only) are available for dtype and device dispatching: #include \u003ctorch/headeronly/core/Dispatch.h\u003e THO_DISPATCH_FLOATING_TYPES(tensor.scalar_type(), \"my_kernel\", [\u0026] { // scalar_t is the resolved type auto* data = tensor.data_ptr\u003cscalar_t\u003e(); }); Full API List# For the complete list of header-only APIs, see torch/header_only_apis.txt in the PyTorch source tree. Stable Operators# Tensor Creation# Warning doxygenfunction: Cannot find function \u201ctorch::stable::empty\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::empty_like\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::new_empty\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::new_zeros\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::full\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::from_blob\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Tensor Manipulation# Warning doxygenfunction: Cannot find function \u201ctorch::stable::clone\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::contiguous\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::reshape\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::view\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::flatten\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::squeeze\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::unsqueeze\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::transpose\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::select\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::narrow\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::pad\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Device and Type Conversion# Warning doxygenfunction: Cannot find function \u201ctorch::stable::to\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::to\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::fill_\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::zero_\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::copy_\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::matmul\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::amax\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::amax\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::sum\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::sum_out\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::subtract\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::parallel_for\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::get_num_threads\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Parallelization Utilities# Warning doxygenfunction: Cannot find function \u201ctorch::stable::parallel_for\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml Warning doxygenfunction: Cannot find function \u201ctorch::stable::get_num_threads\u201d in doxygen xml output for project \u201cPyTorch\u201d from directory: /var/lib/jenkins/workspace/docs/cpp/build/xml",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/stable.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>