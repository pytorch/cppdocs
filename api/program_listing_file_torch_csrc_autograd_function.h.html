
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Program Listing for File function.h &#8212; PyTorch main documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=047068a3" />
    <link rel="stylesheet" type="text/css" href="../_static/collapsible-lists/css/tree_view.css?v=a885cde7" />
    <link rel="stylesheet" type="text/css" href="../_static/cpp_theme.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=a8da1a53"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js?v=73120307"></script>
    <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js?v=660e4f45"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'api/program_listing_file_torch_csrc_autograd_function.h';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="File functional.h" href="file_torch_csrc_api_include_torch_nn_functional.h.html" />
    <link rel="prev" title="File function.h" href="file_torch_csrc_autograd_function.h.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->


<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'main');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->

<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>

<body data-feedback-url="https://github.com/pytorch/pytorch" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                <span>Learn</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started/locally">
                  <span class=dropdown-title>Get Started</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
                  <span class="dropdown-title">Webinars</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Community</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
                  <span class="dropdown-title">Join the Ecosystem</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
                  <span class="dropdown-title">Community Hub</span>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
                  <span class="dropdown-title">Forums</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
                  <span class="dropdown-title">Contributor Awards</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
                  <span class="dropdown-title">Community Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
                  <span class="dropdown-title">PyTorch Ambassadors</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Projects</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
                  <span class="dropdown-title">vLLM</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
                  <span class="dropdown-title">DeepSpeed</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
                  <span class="dropdown-title">Host Your Project</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/ray/">
                  <span class="dropdown-title">RAY</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span> Docs</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/domains">
                  <span class="dropdown-title">Domains</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Blogs & News</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">Blog</span>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/announcements">
                  <span class="dropdown-title">Announcements</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
                  <span class="dropdown-title">Case Studies</span>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                </a>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>About</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/members">
                  <span class="dropdown-title">Members</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact">
                  <span class="dropdown-title">Contact</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/wp-content/uploads/2025/09/pytorch_brand_guide_091925a.pdf">
                  <span class="dropdown-title">Brand Guidelines</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown main-menu-button">
              <a href="https://pytorch.org/join" data-cta="join">
                JOIN
              </a>
            </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>Learn</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/get-started/locally">Get Started</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials">Tutorials</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
           </li>
           <li>
            <a href="https://pytorch.org/webinars/">Webinars</a>
          </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a>Community</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Landscape</a>
          </li>
          <li>
             <a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
           </li>
           <li>
             <a href="https://pytorch.org/community-hub/">Community Hub</a>
           </li>
           <li>
             <a href="https://discuss.pytorch.org/">Forums</a>
           </li>
           <li>
             <a href="https://pytorch.org/resources">Developer Resources</a>
           </li>
           <li>
             <a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
           </li>
           <li>
            <a href="https://pytorch.org/community-events/">Community Events</a>
          </li>
          <li>
            <a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
          </li>
       </ul>

         <li class="resources-mobile-menu-title">
           <a>Projects</a>
         </li>

         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
           </li>

           <li>
             <a href="https://pytorch.org/projects/vllm/">vLLM</a>
           </li>
           <li>
            <a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
          </li>
          <li>
             <a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Docs</a>
         </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/stable/index.html">PyTorch</a>
          </li>

          <li>
            <a href="https://pytorch.org/domains">Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>
          <li>
            <a href="https://pytorch.org/announcements">Announcements</a>
          </li>

          <li>
            <a href="https://pytorch.org/case-studies/">Case Studies</a>
          </li>
          <li>
            <a href="https://pytorch.org/events">Events</a>
          </li>
          <li>
             <a href="https://pytorch.org/newsletter">Newsletter</a>
           </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="https://pytorch.org/members">Members</a>
          </li>
          <li>
            <a href="https://pytorch.org/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="https://pytorch.org/tac">Technical Advisory Council</a>
         </li>
         <li>
             <a href="https://pytorch.org/credits">Cloud Credit Program</a>
          </li>
          <li>
             <a href="https://pytorch.org/staff">Staff</a>
          </li>
          <li>
             <a href="https://pytorch.org/contact">Contact</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../index.html" class="version">main</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../installing.html">
    Installing C++ Distributions of PyTorch
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../frontend.html">
    The C++ Frontend
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../stable.html">
    Torch Stable API
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="library_root.html">
    Library API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/faq.html">
    FAQ
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/inference_mode.html">
    Inference Mode
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/maybe_owned.html">
    MaybeOwned<Tensor>
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/tensor_basics.html">
    Tensor Basics
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/tensor_creation.html">
    Tensor Creation API
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/tensor_cuda_stream.html">
    Tensor CUDA Stream API
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/tensor_indexing.html">
    Tensor Indexing API
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/versioning.html">
    Library Versioning
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="PyTorch Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyTorch Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../installing.html">
    Installing C++ Distributions of PyTorch
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../frontend.html">
    The C++ Frontend
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../stable.html">
    Torch Stable API
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="library_root.html">
    Library API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/inference_mode.html">
    Inference Mode
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/maybe_owned.html">
    MaybeOwned<Tensor>
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/tensor_basics.html">
    Tensor Basics
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/tensor_creation.html">
    Tensor Creation API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/tensor_cuda_stream.html">
    Tensor CUDA Stream API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/tensor_indexing.html">
    Tensor Indexing API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/versioning.html">
    Library Versioning
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="PyTorch Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyTorch Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_at.html">Namespace at</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_at__detail.html">Namespace at::detail</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_at__indexing.html">Namespace at::indexing</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_at__native.html">Namespace at::native</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_at__symint.html">Namespace at::symint</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_c10.html">Namespace c10</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_c10__cuda.html">Namespace c10::cuda</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_c10__detail.html">Namespace c10::detail</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_c10__detail_.html">Namespace c10::detail_</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_c10__ivalue.html">Namespace c10::ivalue</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_c10__WarningUtils.html">Namespace c10::WarningUtils</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_c10__xpu.html">Namespace c10::xpu</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_caffe2.html">Namespace caffe2</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_std.html">Namespace std</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch.html">Namespace torch</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__autograd.html">Namespace torch::autograd</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__autograd__detail.html">Namespace torch::autograd::detail</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__autograd__forward_ad.html">Namespace torch::autograd::forward_ad</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__cuda.html">Namespace torch::cuda</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__data.html">Namespace torch::data</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__data__datasets.html">Namespace torch::data::datasets</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__data__datasets__detail.html">Namespace torch::data::datasets::detail</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__data__detail.html">Namespace torch::data::detail</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__data__detail__sequencers.html">Namespace torch::data::detail::sequencers</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__data__detail__sequencers__detail.html">Namespace torch::data::detail::sequencers::detail</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__data__example.html">Namespace torch::data::example</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__data__samplers.html">Namespace torch::data::samplers</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__data__transforms.html">Namespace torch::data::transforms</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__detail.html">Namespace torch::detail</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__enumtype.html">Namespace torch::enumtype</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__fft.html">Namespace torch::fft</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__jit.html">Namespace torch::jit</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__jit__detail.html">Namespace torch::jit::detail</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__jit__script.html">Namespace torch::jit::script</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__mps.html">Namespace torch::mps</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__nativert.html">Namespace torch::nativert</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__nested.html">Namespace torch::nested</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__nn.html">Namespace torch::nn</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__nn__%40150.html">Namespace torch::nn::@150</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__nn__detail.html">Namespace torch::nn::detail</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__nn__functional.html">Namespace torch::nn::functional</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__nn__functions.html">Namespace torch::nn::functions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__nn__init.html">Namespace torch::nn::init</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__nn__modules.html">Namespace torch::nn::modules</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__nn__modules__utils.html">Namespace torch::nn::modules::utils</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__nn__parallel.html">Namespace torch::nn::parallel</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__nn__utils.html">Namespace torch::nn::utils</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__nn__utils__rnn.html">Namespace torch::nn::utils::rnn</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__optim.html">Namespace torch::optim</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__optim__detail.html">Namespace torch::optim::detail</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__python.html">Namespace torch::python</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__python__detail.html">Namespace torch::python::detail</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__serialize.html">Namespace torch::serialize</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__special.html">Namespace torch::special</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__stable.html">Namespace torch::stable</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__stable__accelerator.html">Namespace torch::stable::accelerator</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__stable__accelerator__%40196.html">Namespace torch::stable::accelerator::@196</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__stable__detail.html">Namespace torch::stable::detail</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="namespace_torch__xpu.html">Namespace torch::xpu</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structat_1_1native_1_1_activation_descriptor.html">Struct ActivationDescriptor</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structat_1_1native_1_1_convolution_descriptor.html">Struct ConvolutionDescriptor</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structat_1_1native_1_1_c_t_c_loss_descriptor.html">Struct CTCLossDescriptor</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structat_1_1native_1_1_descriptor_deleter.html">Template Struct DescriptorDeleter</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structat_1_1native_1_1_dfti_descriptor_deleter.html">Struct DftiDescriptorDeleter</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structat_1_1native_1_1_dropout_descriptor.html">Struct DropoutDescriptor</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structat_1_1native_1_1_r_n_n_descriptor.html">Struct RNNDescriptor</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structat_1_1native_1_1_spatial_transformer_descriptor.html">Struct SpatialTransformerDescriptor</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_capsule.html">Struct Capsule</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1cuda_1_1_c_u_d_a_guard.html">Struct CUDAGuard</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1cuda_1_1_c_u_d_a_multi_stream_guard.html">Struct CUDAMultiStreamGuard</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1cuda_1_1_c_u_d_a_stream_guard.html">Struct CUDAStreamGuard</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1cuda_1_1_optional_c_u_d_a_guard.html">Struct OptionalCUDAGuard</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1cuda_1_1_optional_c_u_d_a_stream_guard.html">Struct OptionalCUDAStreamGuard</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_device.html">Struct Device</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_exclusively_owned_traits_3_01at_1_1_tensor_01_4.html">Template Struct ExclusivelyOwnedTraits&lt; at::Tensor &gt;</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_i_value.html">Struct IValue</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_i_value_1_1_comp_aliased_i_values.html">Struct IValue::CompAliasedIValues</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_i_value_1_1_comp_identity_i_values.html">Struct IValue::CompIdentityIValues</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1ivalue_1_1_complex_holder.html">Struct ComplexHolder</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_i_value_1_1_hash_aliased_i_value.html">Struct IValue::HashAliasedIValue</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_i_value_1_1_hash_identity_i_value.html">Struct IValue::HashIdentityIValue</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1ivalue_1_1_stream_data3_holder.html">Struct StreamData3Holder</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_i_value_1_1_tag_type.html">Template Struct IValue::TagType</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_maybe_owned_traits_3_01at_1_1_tensor_01_4.html">Template Struct MaybeOwnedTraits&lt; at::Tensor &gt;</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_optional_array.html">Template Struct OptionalArray</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_strong_type_ptr.html">Struct StrongTypePtr</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_warning_utils_1_1_warn_always.html">Struct WarnAlways</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_weak_i_value.html">Struct WeakIValue</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_weak_or_strong_compilation_unit.html">Struct WeakOrStrongCompilationUnit</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_weak_or_strong_type_ptr.html">Struct WeakOrStrongTypePtr</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structc10_1_1_weak_type_ptr.html">Struct WeakTypePtr</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1autograd_1_1_autograd_context.html">Struct AutogradContext</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1autograd_1_1_cpp_node.html">Template Struct CppNode</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1autograd_1_1detail_1_1_make_next_function_list.html">Struct MakeNextFunctionList</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1autograd_1_1_extract_variables.html">Struct ExtractVariables</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1autograd_1_1_function.html">Template Struct Function</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1autograd_1_1_node.html">Struct Node</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1autograd_1_1_node_1_1undefined__input.html">Struct Node::undefined_input</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1autograd_1_1_traceable_function.html">Struct TraceableFunction</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1autograd_1_1_type_and_size.html">Struct TypeAndSize</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1_data_loader_base_1_1_job.html">Struct DataLoaderBase::Job</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1_data_loader_base_1_1_quit_worker.html">Struct DataLoaderBase::QuitWorker</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1_data_loader_base_1_1_result.html">Struct DataLoaderBase::Result</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1_data_loader_base_1_1_sequenced.html">Struct DataLoaderBase::Sequenced</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1_data_loader_options.html">Struct DataLoaderOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1datasets_1_1_chunk_dataset_options.html">Struct ChunkDatasetOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1datasets_1_1detail_1_1_batch_data_buffer_1_1_unwrapped_batch_data.html">Struct BatchDataBuffer::UnwrappedBatchData</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1datasets_1_1detail_1_1is__optional.html">Template Struct is_optional</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1datasets_1_1_tensor_dataset.html">Struct TensorDataset</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1detail_1_1_iterator_impl.html">Template Struct IteratorImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1detail_1_1_sentinel_iterator.html">Template Struct SentinelIterator</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1detail_1_1sequencers_1_1_no_sequencer.html">Template Struct NoSequencer</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1detail_1_1sequencers_1_1_ordered_sequencer.html">Template Struct OrderedSequencer</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1detail_1_1sequencers_1_1_sequencer.html">Template Struct Sequencer</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1detail_1_1_valid_iterator.html">Template Struct ValidIterator</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1_example.html">Template Struct Example</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1_example_3_01_data_00_01example_1_1_no_target_01_4.html">Template Struct Example&lt; Data, example::NoTarget &gt;</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1_full_data_loader_options.html">Struct FullDataLoaderOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1samplers_1_1_batch_size.html">Struct BatchSize</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1samplers_1_1_custom_batch_request.html">Struct CustomBatchRequest</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1transforms_1_1_normalize.html">Template Struct Normalize</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1transforms_1_1_stack.html">Template Struct Stack</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1transforms_1_1_stack_3_01_example_3_4_01_4.html">Template Struct Stack&lt; Example&lt;  &gt; &gt;</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1transforms_1_1_stack_3_01_tensor_example_01_4.html">Template Struct Stack&lt; TensorExample &gt;</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1data_1_1_worker_exception.html">Struct WorkerException</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1__compute__enum__name.html">Struct _compute_enum_name</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_area.html">Struct kArea</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_batch_mean.html">Struct kBatchMean</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_bicubic.html">Struct kBicubic</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_bilinear.html">Struct kBilinear</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_border.html">Struct kBorder</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_circular.html">Struct kCircular</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_constant.html">Struct kConstant</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_conv1_d.html">Struct kConv1D</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_conv2_d.html">Struct kConv2D</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_conv3_d.html">Struct kConv3D</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_conv_transpose1_d.html">Struct kConvTranspose1D</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_conv_transpose2_d.html">Struct kConvTranspose2D</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_conv_transpose3_d.html">Struct kConvTranspose3D</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_fan_in.html">Struct kFanIn</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_fan_out.html">Struct kFanOut</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_g_e_l_u.html">Struct kGELU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_g_r_u.html">Struct kGRU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_leaky_re_l_u.html">Struct kLeakyReLU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_linear.html">Struct kLinear</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_l_s_t_m.html">Struct kLSTM</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_max.html">Struct kMax</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_mean.html">Struct kMean</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_mish.html">Struct kMish</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_nearest.html">Struct kNearest</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_nearest_exact.html">Struct kNearestExact</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_none.html">Struct kNone</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_reflect.html">Struct kReflect</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_reflection.html">Struct kReflection</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_re_l_u.html">Struct kReLU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_replicate.html">Struct kReplicate</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_r_n_n___r_e_l_u.html">Struct kRNN_RELU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_r_n_n___t_a_n_h.html">Struct kRNN_TANH</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_same.html">Struct kSame</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_sigmoid.html">Struct kSigmoid</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_si_l_u.html">Struct kSiLU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_sum.html">Struct kSum</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_tanh.html">Struct kTanh</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_trilinear.html">Struct kTrilinear</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_valid.html">Struct kValid</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1enumtype_1_1k_zeros.html">Struct kZeros</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1_init_lambda.html">Template Struct InitLambda</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1jit_1_1detail_1_1_attribute_policy.html">Struct AttributePolicy</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1jit_1_1detail_1_1_buffer_policy.html">Struct BufferPolicy</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1jit_1_1detail_1_1_module_policy.html">Struct ModulePolicy</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1jit_1_1detail_1_1_named_policy.html">Template Struct NamedPolicy</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1jit_1_1detail_1_1_parameter_policy.html">Struct ParameterPolicy</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1jit_1_1detail_1_1_slot_cursor.html">Struct SlotCursor</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1jit_1_1_module.html">Struct Module</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1jit_1_1_named.html">Template Struct Named</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1jit_1_1_register_operators.html">Struct RegisterOperators</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1jit_1_1slot__iterator__impl.html">Template Struct slot_iterator_impl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1jit_1_1slot__list__impl.html">Template Struct slot_list_impl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_adaptive_avg_pool_options.html">Template Struct AdaptiveAvgPoolOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_adaptive_log_softmax_with_loss_options.html">Struct AdaptiveLogSoftmaxWithLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_adaptive_max_pool_options.html">Template Struct AdaptiveMaxPoolOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_any_module_holder.html">Template Struct AnyModuleHolder</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_any_module_holder_1_1_checked_getter.html">Struct AnyModuleHolder::CheckedGetter</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_any_module_holder_1_1_invoke_forward.html">Struct AnyModuleHolder::InvokeForward</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_any_module_placeholder.html">Struct AnyModulePlaceholder</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_any_value_1_1_holder.html">Template Struct AnyValue::Holder</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_any_value_1_1_placeholder.html">Struct AnyValue::Placeholder</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_a_s_moutput.html">Struct ASMoutput</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_avg_pool_options.html">Template Struct AvgPoolOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_batch_norm_options.html">Struct BatchNormOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_b_c_e_loss_impl.html">Struct BCELossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_b_c_e_loss_options.html">Struct BCELossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_b_c_e_with_logits_loss_impl.html">Struct BCEWithLogitsLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_b_c_e_with_logits_loss_options.html">Struct BCEWithLogitsLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_bilinear_options.html">Struct BilinearOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_c_e_l_u_options.html">Struct CELUOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_constant_pad_options.html">Template Struct ConstantPadOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_conv_options.html">Template Struct ConvOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_conv_transpose_options.html">Template Struct ConvTransposeOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_cosine_embedding_loss_impl.html">Struct CosineEmbeddingLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_cosine_embedding_loss_options.html">Struct CosineEmbeddingLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_cosine_similarity_options.html">Struct CosineSimilarityOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_cross_entropy_loss_impl.html">Struct CrossEntropyLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_cross_entropy_loss_options.html">Struct CrossEntropyLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_cross_map_l_r_n2d_options.html">Struct CrossMapLRN2dOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_c_t_c_loss_impl.html">Struct CTCLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_c_t_c_loss_options.html">Struct CTCLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1detail_1_1_conv_nd_options.html">Template Struct ConvNdOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1detail_1_1_r_n_n_cell_options_base.html">Struct RNNCellOptionsBase</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1detail_1_1_r_n_n_options_base.html">Struct RNNOptionsBase</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_dropout_options.html">Struct DropoutOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_e_l_u_options.html">Struct ELUOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_embedding_bag_from_pretrained_options.html">Struct EmbeddingBagFromPretrainedOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_embedding_bag_options.html">Struct EmbeddingBagOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_embedding_from_pretrained_options.html">Struct EmbeddingFromPretrainedOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_embedding_options.html">Struct EmbeddingOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_flatten_options.html">Struct FlattenOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_fold_options.html">Struct FoldOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_fractional_max_pool_options.html">Template Struct FractionalMaxPoolOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_alpha_dropout_func_options.html">Struct AlphaDropoutFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_batch_norm_func_options.html">Struct BatchNormFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_conv_func_options.html">Template Struct ConvFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_conv_transpose_func_options.html">Template Struct ConvTransposeFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_dropout_func_options.html">Struct DropoutFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_embedding_bag_func_options.html">Struct EmbeddingBagFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_embedding_func_options.html">Struct EmbeddingFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_feature_alpha_dropout_func_options.html">Struct FeatureAlphaDropoutFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_grid_sample_func_options.html">Struct GridSampleFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_group_norm_func_options.html">Struct GroupNormFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_gumbel_softmax_func_options.html">Struct GumbelSoftmaxFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_instance_norm_func_options.html">Struct InstanceNormFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_interpolate_func_options.html">Struct InterpolateFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_layer_norm_func_options.html">Struct LayerNormFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_log_softmax_func_options.html">Struct LogSoftmaxFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_max_unpool_func_options.html">Template Struct MaxUnpoolFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_multihead_attention_forward_func_options.html">Struct MultiheadAttentionForwardFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_normalize_func_options.html">Struct NormalizeFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_pad_func_options.html">Struct PadFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_r_re_l_u_func_options.html">Struct RReLUFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_softmax_func_options.html">Struct SoftmaxFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1functional_1_1_softmin_func_options.html">Struct SoftminFuncOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_g_e_l_u_options.html">Struct GELUOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_g_l_u_options.html">Struct GLUOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_group_norm_options.html">Struct GroupNormOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_g_r_u_cell_options.html">Struct GRUCellOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_g_r_u_options.html">Struct GRUOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_hardshrink_options.html">Struct HardshrinkOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_hardtanh_options.html">Struct HardtanhOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_hinge_embedding_loss_impl.html">Struct HingeEmbeddingLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_hinge_embedding_loss_options.html">Struct HingeEmbeddingLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_huber_loss_impl.html">Struct HuberLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_huber_loss_options.html">Struct HuberLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_instance_norm_options.html">Struct InstanceNormOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_k_l_div_loss_impl.html">Struct KLDivLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_k_l_div_loss_options.html">Struct KLDivLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_l1_loss_impl.html">Struct L1LossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_l1_loss_options.html">Struct L1LossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_layer_norm_options.html">Struct LayerNormOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_leaky_re_l_u_options.html">Struct LeakyReLUOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_linear_options.html">Struct LinearOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_local_response_norm_options.html">Struct LocalResponseNormOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_log_softmax_options.html">Struct LogSoftmaxOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_l_p_pool_options.html">Template Struct LPPoolOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_l_s_t_m_cell_options.html">Struct LSTMCellOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_l_s_t_m_options.html">Struct LSTMOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_margin_ranking_loss_impl.html">Struct MarginRankingLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_margin_ranking_loss_options.html">Struct MarginRankingLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_max_pool_options.html">Template Struct MaxPoolOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_max_unpool_options.html">Template Struct MaxUnpoolOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_m_s_e_loss_impl.html">Struct MSELossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_m_s_e_loss_options.html">Struct MSELossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_multihead_attention_options.html">Struct MultiheadAttentionOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_multi_label_margin_loss_impl.html">Struct MultiLabelMarginLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_multi_label_margin_loss_options.html">Struct MultiLabelMarginLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_multi_label_soft_margin_loss_impl.html">Struct MultiLabelSoftMarginLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_multi_label_soft_margin_loss_options.html">Struct MultiLabelSoftMarginLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_multi_margin_loss_impl.html">Struct MultiMarginLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_multi_margin_loss_options.html">Struct MultiMarginLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_n_l_l_loss_impl.html">Struct NLLLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_n_l_l_loss_options.html">Struct NLLLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_pairwise_distance_options.html">Struct PairwiseDistanceOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_pixel_shuffle_impl.html">Struct PixelShuffleImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_pixel_shuffle_options.html">Struct PixelShuffleOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_pixel_unshuffle_impl.html">Struct PixelUnshuffleImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_pixel_unshuffle_options.html">Struct PixelUnshuffleOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_poisson_n_l_l_loss_impl.html">Struct PoissonNLLLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_poisson_n_l_l_loss_options.html">Struct PoissonNLLLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_p_re_l_u_options.html">Struct PReLUOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_reflection_pad_options.html">Template Struct ReflectionPadOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_re_l_u6_options.html">Struct ReLU6Options</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_re_l_u_options.html">Struct ReLUOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_replication_pad_options.html">Template Struct ReplicationPadOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_r_n_n_cell_options.html">Struct RNNCellOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_r_n_n_options.html">Struct RNNOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_r_re_l_u_options.html">Struct RReLUOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_s_e_l_u_options.html">Struct SELUOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_smooth_l1_loss_impl.html">Struct SmoothL1LossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_smooth_l1_loss_options.html">Struct SmoothL1LossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_soft_margin_loss_impl.html">Struct SoftMarginLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_soft_margin_loss_options.html">Struct SoftMarginLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_softmax_options.html">Struct SoftmaxOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_softmin_options.html">Struct SoftminOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_softplus_options.html">Struct SoftplusOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_softshrink_options.html">Struct SoftshrinkOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_threshold_options.html">Struct ThresholdOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_transformer_decoder_layer_options.html">Struct TransformerDecoderLayerOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_transformer_decoder_options.html">Struct TransformerDecoderOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_transformer_encoder_layer_options.html">Struct TransformerEncoderLayerOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_transformer_encoder_options.html">Struct TransformerEncoderOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_transformer_options.html">Struct TransformerOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_triplet_margin_loss_impl.html">Struct TripletMarginLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_triplet_margin_loss_options.html">Struct TripletMarginLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_triplet_margin_with_distance_loss_impl.html">Struct TripletMarginWithDistanceLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_triplet_margin_with_distance_loss_options.html">Struct TripletMarginWithDistanceLossOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_unflatten_options.html">Struct UnflattenOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_unfold_options.html">Struct UnfoldOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_upsample_options.html">Struct UpsampleOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1nn_1_1_zero_pad_options.html">Template Struct ZeroPadOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1optim_1_1_adagrad_options.html">Struct AdagradOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1optim_1_1_adagrad_param_state.html">Struct AdagradParamState</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1optim_1_1_adam_options.html">Struct AdamOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1optim_1_1_adam_param_state.html">Struct AdamParamState</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1optim_1_1_adam_w_options.html">Struct AdamWOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1optim_1_1_adam_w_param_state.html">Struct AdamWParamState</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1optim_1_1_l_b_f_g_s_options.html">Struct LBFGSOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1optim_1_1_l_b_f_g_s_param_state.html">Struct LBFGSParamState</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1optim_1_1_r_m_sprop_options.html">Struct RMSpropOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1optim_1_1_r_m_sprop_param_state.html">Struct RMSpropParamState</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1optim_1_1_s_g_d_options.html">Struct SGDOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1optim_1_1_s_g_d_param_state.html">Struct SGDParamState</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1stable_1_1detail_1_1boxer.html">Template Struct boxer</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1stable_1_1detail_1_1boxer__impl.html">Template Struct boxer_impl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1stable_1_1detail_1_1boxer__impl_3_01_return_type_00_01torch_1_1headeronly_1_1gutsa0940d39d9dd89f80a80e036730770c0.html">Template Struct boxer_impl&lt; ReturnType, torch::headeronly::guts::typelist::typelist&lt; ParameterTypes &gt;, FuncT, func &gt;</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1stable_1_1detail_1_1boxer__impl_3_01void_00_01torch_1_1headeronly_1_1guts_1_1type99181efc5fb2ad5a7b9ab621d41cde72.html">Template Struct boxer_impl&lt; void, torch::headeronly::guts::typelist::typelist&lt; ParameterTypes &gt;, FuncT, func &gt;</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1stable_1_1detail_1_1_unbox_type.html">Template Struct UnboxType</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="structtorch_1_1stable_1_1detail_1_1_unbox_type_3_01torch_1_1headeronly_1_1_header_only_array_ref_3_01_t_01_4_01_4.html">Template Struct UnboxType&lt; torch::headeronly::HeaderOnlyArrayRef&lt; T &gt; &gt;</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classat_1_1native_1_1_descriptor.html">Template Class Descriptor</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classat_1_1native_1_1_dfti_descriptor.html">Class DftiDescriptor</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classat_1_1native_1_1_filter_descriptor.html">Class FilterDescriptor</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classat_1_1native_1_1_r_n_n_data_descriptor.html">Class RNNDataDescriptor</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classat_1_1native_1_1_tensor_descriptor.html">Class TensorDescriptor</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classat_1_1_optional_tensor_ref.html">Class OptionalTensorRef</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classat_1_1_tensor.html">Class Tensor</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classat_1_1_tensor_ref.html">Class TensorRef</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_accelerator_error.html">Class AcceleratorError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_array_ref.html">Template Class ArrayRef</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_buffer_error.html">Class BufferError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1cuda_1_1_c_u_d_a_stream.html">Class CUDAStream</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_dict.html">Template Class Dict</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_dist_backend_error.html">Class DistBackendError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_dist_error.html">Class DistError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_dist_network_error.html">Class DistNetworkError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_dist_queue_empty_error.html">Class DistQueueEmptyError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_dist_store_error.html">Class DistStoreError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_enforce_finite_error.html">Class EnforceFiniteError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_error.html">Class Error</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_error_always_show_cpp_stacktrace.html">Class ErrorAlwaysShowCppStacktrace</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_i_list_ref.html">Template Class IListRef</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_index_error.html">Class IndexError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_lin_alg_error.html">Class LinAlgError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_list.html">Template Class List</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_not_implemented_error.html">Class NotImplementedError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_onnxfi_backend_system_error.html">Class OnnxfiBackendSystemError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_optional_array_ref.html">Template Class OptionalArrayRef</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_out_of_memory_error.html">Class OutOfMemoryError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_syntax_error.html">Class SyntaxError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_type_error.html">Class TypeError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_value_error.html">Class ValueError</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_warning.html">Class Warning</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_warning_1_1_deprecation_warning.html">Class Warning::DeprecationWarning</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_warning_1_1_user_warning.html">Class Warning::UserWarning</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_warning_handler.html">Class WarningHandler</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1_warning_utils_1_1_warning_handler_guard.html">Class WarningHandlerGuard</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classc10_1_1xpu_1_1_x_p_u_stream.html">Class XPUStream</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1autograd_1_1_node_guard.html">Class NodeGuard</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1class__.html">Template Class class_</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1_cpp_function.html">Class CppFunction</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1_custom_class_holder.html">Class CustomClassHolder</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1_data_loader_base.html">Template Class DataLoaderBase</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1datasets_1_1_batch_dataset.html">Template Class BatchDataset</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1datasets_1_1_chunk_data_reader.html">Template Class ChunkDataReader</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1datasets_1_1_chunk_dataset.html">Template Class ChunkDataset</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1datasets_1_1_dataset.html">Template Class Dataset</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1datasets_1_1detail_1_1_batch_data_buffer.html">Template Class BatchDataBuffer</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1datasets_1_1_map_dataset.html">Template Class MapDataset</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1datasets_1_1_m_n_i_s_t.html">Class MNIST</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1datasets_1_1_shared_batch_dataset.html">Template Class SharedBatchDataset</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1datasets_1_1_stateful_dataset.html">Template Class StatefulDataset</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1detail_1_1_data_shuttle.html">Template Class DataShuttle</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1detail_1_1_queue.html">Template Class Queue</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1_iterator.html">Template Class Iterator</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1samplers_1_1_distributed_random_sampler.html">Class DistributedRandomSampler</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1samplers_1_1_distributed_sampler.html">Template Class DistributedSampler</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1samplers_1_1_distributed_sequential_sampler.html">Class DistributedSequentialSampler</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1samplers_1_1_random_sampler.html">Class RandomSampler</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1samplers_1_1_sampler.html">Template Class Sampler</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1samplers_1_1_sequential_sampler.html">Class SequentialSampler</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1samplers_1_1_stream_sampler.html">Class StreamSampler</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1_stateful_data_loader.html">Template Class StatefulDataLoader</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1_stateless_data_loader.html">Template Class StatelessDataLoader</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1transforms_1_1_batch_lambda.html">Template Class BatchLambda</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1transforms_1_1_batch_transform.html">Template Class BatchTransform</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1transforms_1_1_lambda.html">Template Class Lambda</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1transforms_1_1_tensor_lambda.html">Template Class TensorLambda</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1transforms_1_1_tensor_transform.html">Template Class TensorTransform</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1data_1_1transforms_1_1_transform.html">Template Class Transform</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1detail_1_1_class_not_selected.html">Class ClassNotSelected</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1detail_1_1_selective_str.html">Template Class SelectiveStr</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1detail_1_1_torch_library_init.html">Class TorchLibraryInit</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1_expanding_array.html">Template Class ExpandingArray</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1_expanding_array_with_optional_elem.html">Template Class ExpandingArrayWithOptionalElem</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1_i_method.html">Class IMethod</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1_library.html">Class Library</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nativert_1_1_model_runner_handle.html">Class ModelRunnerHandle</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_avg_pool1d.html">Class AdaptiveAvgPool1d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_avg_pool1d_impl.html">Class AdaptiveAvgPool1dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_avg_pool2d.html">Class AdaptiveAvgPool2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_avg_pool2d_impl.html">Class AdaptiveAvgPool2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_avg_pool3d.html">Class AdaptiveAvgPool3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_avg_pool3d_impl.html">Class AdaptiveAvgPool3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_avg_pool_impl.html">Template Class AdaptiveAvgPoolImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_log_softmax_with_loss.html">Class AdaptiveLogSoftmaxWithLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_log_softmax_with_loss_impl.html">Class AdaptiveLogSoftmaxWithLossImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_max_pool1d.html">Class AdaptiveMaxPool1d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_max_pool1d_impl.html">Class AdaptiveMaxPool1dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_max_pool2d.html">Class AdaptiveMaxPool2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_max_pool2d_impl.html">Class AdaptiveMaxPool2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_max_pool3d.html">Class AdaptiveMaxPool3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_max_pool3d_impl.html">Class AdaptiveMaxPool3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_adaptive_max_pool_impl.html">Template Class AdaptiveMaxPoolImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_alpha_dropout.html">Class AlphaDropout</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_alpha_dropout_impl.html">Class AlphaDropoutImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_any_module.html">Class AnyModule</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_any_value.html">Class AnyValue</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_avg_pool1d.html">Class AvgPool1d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_avg_pool1d_impl.html">Class AvgPool1dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_avg_pool2d.html">Class AvgPool2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_avg_pool2d_impl.html">Class AvgPool2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_avg_pool3d.html">Class AvgPool3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_avg_pool3d_impl.html">Class AvgPool3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_avg_pool_impl.html">Template Class AvgPoolImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_batch_norm1d.html">Class BatchNorm1d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_batch_norm1d_impl.html">Class BatchNorm1dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_batch_norm2d.html">Class BatchNorm2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_batch_norm2d_impl.html">Class BatchNorm2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_batch_norm3d.html">Class BatchNorm3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_batch_norm3d_impl.html">Class BatchNorm3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_batch_norm_impl_base.html">Template Class BatchNormImplBase</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_b_c_e_loss.html">Class BCELoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_b_c_e_with_logits_loss.html">Class BCEWithLogitsLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_bilinear.html">Class Bilinear</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_bilinear_impl.html">Class BilinearImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_c_e_l_u.html">Class CELU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_c_e_l_u_impl.html">Class CELUImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html">Template Class Cloneable</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_constant_pad1d.html">Class ConstantPad1d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_constant_pad1d_impl.html">Class ConstantPad1dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_constant_pad2d.html">Class ConstantPad2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_constant_pad2d_impl.html">Class ConstantPad2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_constant_pad3d.html">Class ConstantPad3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_constant_pad3d_impl.html">Class ConstantPad3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_constant_pad_impl.html">Template Class ConstantPadImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_conv1d.html">Class Conv1d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_conv1d_impl.html">Class Conv1dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_conv2d.html">Class Conv2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_conv2d_impl.html">Class Conv2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_conv3d.html">Class Conv3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_conv3d_impl.html">Class Conv3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_conv_nd_impl.html">Template Class ConvNdImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_conv_transpose1d.html">Class ConvTranspose1d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_conv_transpose1d_impl.html">Class ConvTranspose1dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_conv_transpose2d.html">Class ConvTranspose2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_conv_transpose2d_impl.html">Class ConvTranspose2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_conv_transpose3d.html">Class ConvTranspose3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_conv_transpose3d_impl.html">Class ConvTranspose3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_conv_transpose_nd_impl.html">Template Class ConvTransposeNdImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_cosine_embedding_loss.html">Class CosineEmbeddingLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_cosine_similarity.html">Class CosineSimilarity</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_cosine_similarity_impl.html">Class CosineSimilarityImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_cross_entropy_loss.html">Class CrossEntropyLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_cross_map_l_r_n2d.html">Class CrossMapLRN2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_cross_map_l_r_n2d_impl.html">Class CrossMapLRN2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_c_t_c_loss.html">Class CTCLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1detail_1_1___dropout_nd.html">Template Class _DropoutNd</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1detail_1_1_r_n_n_cell_impl_base.html">Template Class RNNCellImplBase</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1detail_1_1_r_n_n_impl_base.html">Template Class RNNImplBase</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_dropout.html">Class Dropout</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_dropout2d.html">Class Dropout2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_dropout2d_impl.html">Class Dropout2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_dropout3d.html">Class Dropout3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_dropout3d_impl.html">Class Dropout3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_dropout_impl.html">Class DropoutImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_e_l_u.html">Class ELU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_e_l_u_impl.html">Class ELUImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_embedding.html">Class Embedding</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_embedding_bag.html">Class EmbeddingBag</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_embedding_bag_impl.html">Class EmbeddingBagImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_embedding_impl.html">Class EmbeddingImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_feature_alpha_dropout.html">Class FeatureAlphaDropout</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_feature_alpha_dropout_impl.html">Class FeatureAlphaDropoutImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_flatten.html">Class Flatten</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_flatten_impl.html">Class FlattenImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_fold.html">Class Fold</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_fold_impl.html">Class FoldImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_fractional_max_pool2d.html">Class FractionalMaxPool2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_fractional_max_pool2d_impl.html">Class FractionalMaxPool2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_fractional_max_pool3d.html">Class FractionalMaxPool3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_fractional_max_pool3d_impl.html">Class FractionalMaxPool3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_functional.html">Class Functional</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_functional_impl.html">Class FunctionalImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1functions_1_1_cross_map_l_r_n2d.html">Class CrossMapLRN2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_g_e_l_u.html">Class GELU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_g_e_l_u_impl.html">Class GELUImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_g_l_u.html">Class GLU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_g_l_u_impl.html">Class GLUImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_group_norm.html">Class GroupNorm</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_group_norm_impl.html">Class GroupNormImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_g_r_u.html">Class GRU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_g_r_u_cell.html">Class GRUCell</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_g_r_u_cell_impl.html">Class GRUCellImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_g_r_u_impl.html">Class GRUImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_hardshrink.html">Class Hardshrink</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_hardshrink_impl.html">Class HardshrinkImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_hardtanh.html">Class Hardtanh</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_hardtanh_impl.html">Class HardtanhImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_hinge_embedding_loss.html">Class HingeEmbeddingLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_huber_loss.html">Class HuberLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_identity.html">Class Identity</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_identity_impl.html">Class IdentityImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_instance_norm1d.html">Class InstanceNorm1d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_instance_norm1d_impl.html">Class InstanceNorm1dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_instance_norm2d.html">Class InstanceNorm2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_instance_norm2d_impl.html">Class InstanceNorm2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_instance_norm3d.html">Class InstanceNorm3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_instance_norm3d_impl.html">Class InstanceNorm3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_instance_norm_impl.html">Template Class InstanceNormImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_k_l_div_loss.html">Class KLDivLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_l1_loss.html">Class L1Loss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_layer_norm.html">Class LayerNorm</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_layer_norm_impl.html">Class LayerNormImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_leaky_re_l_u.html">Class LeakyReLU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_leaky_re_l_u_impl.html">Class LeakyReLUImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_linear.html">Class Linear</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_linear_impl.html">Class LinearImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_local_response_norm.html">Class LocalResponseNorm</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_local_response_norm_impl.html">Class LocalResponseNormImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_log_sigmoid.html">Class LogSigmoid</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_log_sigmoid_impl.html">Class LogSigmoidImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_log_softmax.html">Class LogSoftmax</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_log_softmax_impl.html">Class LogSoftmaxImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_l_p_pool1d.html">Class LPPool1d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_l_p_pool1d_impl.html">Class LPPool1dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_l_p_pool2d.html">Class LPPool2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_l_p_pool2d_impl.html">Class LPPool2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_l_p_pool3d.html">Class LPPool3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_l_p_pool3d_impl.html">Class LPPool3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_l_p_pool_impl.html">Template Class LPPoolImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_l_s_t_m.html">Class LSTM</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_l_s_t_m_cell.html">Class LSTMCell</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_l_s_t_m_cell_impl.html">Class LSTMCellImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_l_s_t_m_impl.html">Class LSTMImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_margin_ranking_loss.html">Class MarginRankingLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_max_pool1d.html">Class MaxPool1d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_max_pool1d_impl.html">Class MaxPool1dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_max_pool2d.html">Class MaxPool2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_max_pool2d_impl.html">Class MaxPool2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_max_pool3d.html">Class MaxPool3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_max_pool3d_impl.html">Class MaxPool3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_max_pool_impl.html">Template Class MaxPoolImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_max_unpool1d.html">Class MaxUnpool1d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_max_unpool1d_impl.html">Class MaxUnpool1dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_max_unpool2d.html">Class MaxUnpool2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_max_unpool2d_impl.html">Class MaxUnpool2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_max_unpool3d.html">Class MaxUnpool3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_max_unpool3d_impl.html">Class MaxUnpool3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_max_unpool_impl.html">Template Class MaxUnpoolImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_mish.html">Class Mish</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_mish_impl.html">Class MishImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_module.html">Class Module</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_module_dict.html">Class ModuleDict</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_module_dict_impl.html">Class ModuleDictImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_module_holder.html">Template Class ModuleHolder</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_module_list.html">Class ModuleList</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_module_list_impl.html">Class ModuleListImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_m_s_e_loss.html">Class MSELoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_multihead_attention.html">Class MultiheadAttention</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_multihead_attention_impl.html">Class MultiheadAttentionImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_multi_label_margin_loss.html">Class MultiLabelMarginLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_multi_label_soft_margin_loss.html">Class MultiLabelSoftMarginLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_multi_margin_loss.html">Class MultiMarginLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_named_any_module.html">Class NamedAnyModule</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_n_l_l_loss.html">Class NLLLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_norm_impl_base.html">Template Class NormImplBase</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_pairwise_distance.html">Class PairwiseDistance</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_pairwise_distance_impl.html">Class PairwiseDistanceImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_parameter_dict.html">Class ParameterDict</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_parameter_dict_impl.html">Class ParameterDictImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_parameter_list.html">Class ParameterList</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_parameter_list_impl.html">Class ParameterListImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_pixel_shuffle.html">Class PixelShuffle</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_pixel_unshuffle.html">Class PixelUnshuffle</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_poisson_n_l_l_loss.html">Class PoissonNLLLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_p_re_l_u.html">Class PReLU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_p_re_l_u_impl.html">Class PReLUImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_reflection_pad1d.html">Class ReflectionPad1d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_reflection_pad1d_impl.html">Class ReflectionPad1dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_reflection_pad2d.html">Class ReflectionPad2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_reflection_pad2d_impl.html">Class ReflectionPad2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_reflection_pad3d.html">Class ReflectionPad3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_reflection_pad3d_impl.html">Class ReflectionPad3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_reflection_pad_impl.html">Template Class ReflectionPadImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_re_l_u.html">Class ReLU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_re_l_u6.html">Class ReLU6</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_re_l_u6_impl.html">Class ReLU6Impl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_re_l_u_impl.html">Class ReLUImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_replication_pad1d.html">Class ReplicationPad1d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_replication_pad1d_impl.html">Class ReplicationPad1dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_replication_pad2d.html">Class ReplicationPad2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_replication_pad2d_impl.html">Class ReplicationPad2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_replication_pad3d.html">Class ReplicationPad3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_replication_pad3d_impl.html">Class ReplicationPad3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_replication_pad_impl.html">Template Class ReplicationPadImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_r_n_n.html">Class RNN</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_r_n_n_cell.html">Class RNNCell</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_r_n_n_cell_impl.html">Class RNNCellImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_r_n_n_impl.html">Class RNNImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_r_re_l_u.html">Class RReLU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_r_re_l_u_impl.html">Class RReLUImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_s_e_l_u.html">Class SELU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_s_e_l_u_impl.html">Class SELUImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_sequential.html">Class Sequential</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_sequential_impl.html">Class SequentialImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_sigmoid.html">Class Sigmoid</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_sigmoid_impl.html">Class SigmoidImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_si_l_u.html">Class SiLU</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_si_l_u_impl.html">Class SiLUImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_smooth_l1_loss.html">Class SmoothL1Loss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_soft_margin_loss.html">Class SoftMarginLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_softmax.html">Class Softmax</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_softmax2d.html">Class Softmax2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_softmax2d_impl.html">Class Softmax2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_softmax_impl.html">Class SoftmaxImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_softmin.html">Class Softmin</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_softmin_impl.html">Class SoftminImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_softplus.html">Class Softplus</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_softplus_impl.html">Class SoftplusImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_softshrink.html">Class Softshrink</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_softshrink_impl.html">Class SoftshrinkImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_softsign.html">Class Softsign</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_softsign_impl.html">Class SoftsignImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_tanh.html">Class Tanh</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_tanh_impl.html">Class TanhImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_tanhshrink.html">Class Tanhshrink</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_tanhshrink_impl.html">Class TanhshrinkImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_threshold.html">Class Threshold</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_threshold_impl.html">Class ThresholdImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_transformer.html">Class Transformer</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_transformer_decoder.html">Class TransformerDecoder</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_transformer_decoder_impl.html">Class TransformerDecoderImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_transformer_decoder_layer.html">Class TransformerDecoderLayer</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_transformer_decoder_layer_impl.html">Class TransformerDecoderLayerImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_transformer_encoder.html">Class TransformerEncoder</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_transformer_encoder_impl.html">Class TransformerEncoderImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_transformer_encoder_layer.html">Class TransformerEncoderLayer</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_transformer_encoder_layer_impl.html">Class TransformerEncoderLayerImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_transformer_impl.html">Class TransformerImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_triplet_margin_loss.html">Class TripletMarginLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_triplet_margin_with_distance_loss.html">Class TripletMarginWithDistanceLoss</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_unflatten.html">Class Unflatten</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_unflatten_impl.html">Class UnflattenImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_unfold.html">Class Unfold</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_unfold_impl.html">Class UnfoldImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_upsample.html">Class Upsample</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_upsample_impl.html">Class UpsampleImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1utils_1_1rnn_1_1_packed_sequence.html">Class PackedSequence</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_zero_pad1d.html">Class ZeroPad1d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_zero_pad1d_impl.html">Class ZeroPad1dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_zero_pad2d.html">Class ZeroPad2d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_zero_pad2d_impl.html">Class ZeroPad2dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_zero_pad3d.html">Class ZeroPad3d</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_zero_pad3d_impl.html">Class ZeroPad3dImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1nn_1_1_zero_pad_impl.html">Template Class ZeroPadImpl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1optim_1_1_adagrad.html">Class Adagrad</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1optim_1_1_adam.html">Class Adam</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1optim_1_1_adam_w.html">Class AdamW</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1optim_1_1_l_b_f_g_s.html">Class LBFGS</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1optim_1_1_l_r_scheduler.html">Class LRScheduler</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1optim_1_1_optimizer.html">Class Optimizer</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1optim_1_1_optimizer_cloneable_options.html">Template Class OptimizerCloneableOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1optim_1_1_optimizer_cloneable_param_state.html">Template Class OptimizerCloneableParamState</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1optim_1_1_optimizer_options.html">Class OptimizerOptions</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1optim_1_1_optimizer_param_group.html">Class OptimizerParamGroup</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1optim_1_1_optimizer_param_state.html">Class OptimizerParamState</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1optim_1_1_reduce_l_r_on_plateau_scheduler.html">Class ReduceLROnPlateauScheduler</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1optim_1_1_r_m_sprop.html">Class RMSprop</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1optim_1_1_s_g_d.html">Class SGD</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1optim_1_1_step_l_r.html">Class StepLR</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1_ordered_dict.html">Template Class OrderedDict</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1_ordered_dict_1_1_item.html">Class OrderedDict::Item</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1serialize_1_1_input_archive.html">Class InputArchive</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1serialize_1_1_output_archive.html">Class OutputArchive</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1stable_1_1accelerator_1_1_device_guard.html">Class DeviceGuard</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1stable_1_1accelerator_1_1_stream.html">Class Stream</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1stable_1_1detail_1_1_stable_library.html">Class StableLibrary</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1stable_1_1detail_1_1_stable_torch_library_init.html">Class StableTorchLibraryInit</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1stable_1_1_device.html">Class Device</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="classtorch_1_1stable_1_1_tensor.html">Class Tensor</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="unionat_1_1native_1_1_constant.html">Union Constant</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="unionc10_1_1_i_value_1_1_payload.html">Union IValue::Payload</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="unionc10_1_1_i_value_1_1_payload_1_1_trivially_copyable_payload.html">Union TriviallyCopyablePayload</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_aten.html">Directory aten</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_aten_src.html">Directory src</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_aten_src_ATen.html">Directory ATen</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_aten_src_ATen_core.html">Directory core</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_aten_src_ATen_cuda.html">Directory cuda</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_aten_src_ATen_cudnn.html">Directory cudnn</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_aten_src_ATen_mkl.html">Directory mkl</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_aten_src_ATen_native.html">Directory native</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_build.html">Directory build</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_build_aten.html">Directory aten</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_build_aten_src.html">Directory src</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_build_aten_src_ATen.html">Directory ATen</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_build_aten_src_ATen_core.html">Directory core</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_c10.html">Directory c10</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_c10_core.html">Directory core</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_c10_cuda.html">Directory cuda</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_c10_util.html">Directory util</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_c10_xpu.html">Directory xpu</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch.html">Directory torch</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc.html">Directory csrc</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api.html">Directory api</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include.html">Directory include</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch.html">Directory torch</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_data.html">Directory data</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_data_dataloader.html">Directory dataloader</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_data_datasets.html">Directory datasets</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_data_detail.html">Directory detail</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_data_samplers.html">Directory samplers</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_data_transforms.html">Directory transforms</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_nativert.html">Directory nativert</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_nn.html">Directory nn</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_nn_functional.html">Directory functional</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_nn_modules.html">Directory modules</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_nn_modules_container.html">Directory container</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_nn_options.html">Directory options</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_nn_parallel.html">Directory parallel</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_nn_utils.html">Directory utils</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_optim.html">Directory optim</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_optim_schedulers.html">Directory schedulers</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_python.html">Directory python</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_api_include_torch_serialize.html">Directory serialize</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_autograd.html">Directory autograd</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_autograd_generated.html">Directory generated</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_jit.html">Directory jit</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_jit_api.html">Directory api</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_jit_runtime.html">Directory runtime</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_jit_serialization.html">Directory serialization</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dir_torch_csrc_stable.html">Directory stable</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules__functions.h.html">File _functions.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules__functions.h.html">Program Listing for File _functions.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_stable_accelerator.h.html">File accelerator.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_stable_accelerator.h.html">Program Listing for File accelerator.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_activation.h.html">File activation.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_activation.h.html">Program Listing for File activation.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_activation.h.html">File activation.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_activation.h.html">Program Listing for File activation.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_activation.h.html">File activation.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_activation.h.html">Program Listing for File activation.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_optim_adagrad.h.html">File adagrad.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_optim_adagrad.h.html">Program Listing for File adagrad.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_optim_adam.h.html">File adam.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_optim_adam.h.html">Program Listing for File adam.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_optim_adamw.h.html">File adamw.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_optim_adamw.h.html">Program Listing for File adamw.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_adaptive.h.html">File adaptive.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_adaptive.h.html">Program Listing for File adaptive.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_adaptive.h.html">File adaptive.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_adaptive.h.html">Program Listing for File adaptive.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_all.h.html">File all.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_all.h.html">Program Listing for File all.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_container_any.h.html">File any.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_container_any.h.html">Program Listing for File any.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_container_any_module_holder.h.html">File any_module_holder.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_container_any_module_holder.h.html">Program Listing for File any_module_holder.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_container_any_value.h.html">File any_value.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_container_any_value.h.html">Program Listing for File any_value.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_serialize_archive.h.html">File archive.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_serialize_archive.h.html">Program Listing for File archive.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_arg.h.html">File arg.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_arg.h.html">Program Listing for File arg.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_c10_util_ArrayRef.h.html">File ArrayRef.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_c10_util_ArrayRef.h.html">Program Listing for File ArrayRef.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_ATen.h.html">File ATen.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_ATen.h.html">Program Listing for File ATen.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_autograd.h.html">File autograd.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_autograd.h.html">Program Listing for File autograd.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_autograd_autograd.h.html">File autograd.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_autograd_autograd.h.html">Program Listing for File autograd.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_Backend.h.html">File Backend.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_Backend.h.html">Program Listing for File Backend.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_dataloader_base.h.html">File base.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_dataloader_base.h.html">Program Listing for File base.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_datasets_base.h.html">File base.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_datasets_base.h.html">Program Listing for File base.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_samplers_base.h.html">File base.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_samplers_base.h.html">Program Listing for File base.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_transforms_base.h.html">File base.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_transforms_base.h.html">Program Listing for File base.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_batchnorm.h.html">File batchnorm.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_batchnorm.h.html">Program Listing for File batchnorm.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_batchnorm.h.html">File batchnorm.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_batchnorm.h.html">Program Listing for File batchnorm.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_batchnorm.h.html">File batchnorm.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_batchnorm.h.html">Program Listing for File batchnorm.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_datasets_chunk.h.html">File chunk.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_datasets_chunk.h.html">Program Listing for File chunk.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_utils_clip_grad.h.html">File clip_grad.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_utils_clip_grad.h.html">Program Listing for File clip_grad.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_cloneable.h.html">File cloneable.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_cloneable.h.html">Program Listing for File cloneable.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_transforms_collate.h.html">File collate.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_transforms_collate.h.html">Program Listing for File collate.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_common.h.html">File common.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_common.h.html">Program Listing for File common.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_conv.h.html">File conv.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_conv.h.html">Program Listing for File conv.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_conv.h.html">File conv.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_conv.h.html">Program Listing for File conv.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_conv.h.html">File conv.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_conv.h.html">Program Listing for File conv.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_utils_convert_parameters.h.html">File convert_parameters.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_utils_convert_parameters.h.html">Program Listing for File convert_parameters.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_cuda.h.html">File cuda.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_cuda.h.html">Program Listing for File cuda.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_cuda_CUDAContext.h.html">File CUDAContext.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_cuda_CUDAContext.h.html">Program Listing for File CUDAContext.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_c10_cuda_CUDAGuard.h.html">File CUDAGuard.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_c10_cuda_CUDAGuard.h.html">Program Listing for File CUDAGuard.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_c10_cuda_CUDAStream.h.html">File CUDAStream.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_c10_cuda_CUDAStream.h.html">Program Listing for File CUDAStream.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_samplers_custom_batch_request.h.html">File custom_batch_request.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_samplers_custom_batch_request.h.html">Program Listing for File custom_batch_request.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_custom_class.h.html">File custom_class.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_custom_class.h.html">Program Listing for File custom_class.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_autograd_custom_function.h.html">File custom_function.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_autograd_custom_function.h.html">Program Listing for File custom_function.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_jit_runtime_custom_operator.h.html">File custom_operator.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_jit_runtime_custom_operator.h.html">Program Listing for File custom_operator.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data.h.html">File data.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data.h.html">Program Listing for File data.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_parallel_data_parallel.h.html">File data_parallel.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_parallel_data_parallel.h.html">Program Listing for File data_parallel.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_detail_data_shuttle.h.html">File data_shuttle.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_detail_data_shuttle.h.html">Program Listing for File data_shuttle.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_dataloader.h.html">File dataloader.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_dataloader.h.html">Program Listing for File dataloader.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_dataloader_options.h.html">File dataloader_options.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_dataloader_options.h.html">Program Listing for File dataloader_options.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_datasets.h.html">File datasets.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_datasets.h.html">Program Listing for File datasets.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_cudnn_Descriptors.h.html">File Descriptors.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_cudnn_Descriptors.h.html">Program Listing for File Descriptors.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_mkl_Descriptors.h.html">File Descriptors.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_mkl_Descriptors.h.html">Program Listing for File Descriptors.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_c10_core_Device.h.html">File Device.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_c10_core_Device.h.html">Program Listing for File Device.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_stable_device_struct.h.html">File device_struct.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_stable_device_struct.h.html">Program Listing for File device_struct.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_DeviceGuard.h.html">File DeviceGuard.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_DeviceGuard.h.html">Program Listing for File DeviceGuard.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_c10_core_DeviceType.h.html">File DeviceType.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_c10_core_DeviceType.h.html">Program Listing for File DeviceType.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_distance.h.html">File distance.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_distance.h.html">Program Listing for File distance.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_distance.h.html">File distance.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_distance.h.html">Program Listing for File distance.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_distance.h.html">File distance.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_distance.h.html">Program Listing for File distance.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_samplers_distributed.h.html">File distributed.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_samplers_distributed.h.html">Program Listing for File distributed.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_dropout.h.html">File dropout.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_dropout.h.html">Program Listing for File dropout.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_dropout.h.html">File dropout.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_dropout.h.html">Program Listing for File dropout.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_dropout.h.html">File dropout.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_dropout.h.html">Program Listing for File dropout.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_embedding.h.html">File embedding.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_embedding.h.html">Program Listing for File embedding.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_embedding.h.html">File embedding.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_embedding.h.html">Program Listing for File embedding.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_embedding.h.html">File embedding.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_embedding.h.html">Program Listing for File embedding.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_enum.h.html">File enum.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_enum.h.html">Program Listing for File enum.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_example.h.html">File example.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_example.h.html">Program Listing for File example.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_c10_util_Exception.h.html">File Exception.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_c10_util_Exception.h.html">Program Listing for File Exception.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_expanding_array.h.html">File expanding_array.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_expanding_array.h.html">Program Listing for File expanding_array.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_fft.h.html">File fft.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_fft.h.html">Program Listing for File fft.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_fold.h.html">File fold.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_fold.h.html">Program Listing for File fold.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_fold.h.html">File fold.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_fold.h.html">Program Listing for File fold.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_fold.h.html">File fold.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_fold.h.html">Program Listing for File fold.h</a></li>
</ul>
</details></li>
</ul>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="file_torch_csrc_autograd_function.h.html">File function.h</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Program Listing for File function.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional.h.html">File functional.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional.h.html">Program Listing for File functional.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_container_functional.h.html">File functional.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_container_functional.h.html">Program Listing for File functional.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_build_aten_src_ATen_Functions.h.html">File Functions.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_build_aten_src_ATen_Functions.h.html">Program Listing for File Functions.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_c10_util_Half.h.html">File Half.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_c10_util_Half.h.html">Program Listing for File Half.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_cudnn_Handles.h.html">File Handles.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_cudnn_Handles.h.html">Program Listing for File Handles.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_imethod.h.html">File imethod.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_imethod.h.html">Program Listing for File imethod.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_jit_serialization_import.h.html">File import.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_jit_serialization_import.h.html">Program Listing for File import.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_init.h.html">File init.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_init.h.html">Program Listing for File init.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_python_init.h.html">File init.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_python_init.h.html">Program Listing for File init.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_serialize_input-archive.h.html">File input-archive.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_serialize_input-archive.h.html">Program Listing for File input-archive.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_instancenorm.h.html">File instancenorm.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_instancenorm.h.html">Program Listing for File instancenorm.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_instancenorm.h.html">File instancenorm.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_instancenorm.h.html">Program Listing for File instancenorm.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_instancenorm.h.html">File instancenorm.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_instancenorm.h.html">Program Listing for File instancenorm.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_iterator.h.html">File iterator.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_iterator.h.html">Program Listing for File iterator.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_core_ivalue.h.html">File ivalue.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_core_ivalue.h.html">Program Listing for File ivalue.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_jit.h.html">File jit.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_jit.h.html">Program Listing for File jit.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_transforms_lambda.h.html">File lambda.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_transforms_lambda.h.html">Program Listing for File lambda.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_Layout.h.html">File Layout.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_Layout.h.html">Program Listing for File Layout.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_optim_lbfgs.h.html">File lbfgs.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_optim_lbfgs.h.html">Program Listing for File lbfgs.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_stable_library.h.html">File library.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_stable_library.h.html">Program Listing for File library.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_library.h.html">File library.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_library.h.html">Program Listing for File library.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_linear.h.html">File linear.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_linear.h.html">Program Listing for File linear.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_linear.h.html">File linear.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_linear.h.html">Program Listing for File linear.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_linear.h.html">File linear.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_linear.h.html">Program Listing for File linear.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_loss.h.html">File loss.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_loss.h.html">Program Listing for File loss.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_loss.h.html">File loss.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_loss.h.html">Program Listing for File loss.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_loss.h.html">File loss.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_loss.h.html">Program Listing for File loss.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_optim_schedulers_lr_scheduler.h.html">File lr_scheduler.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_optim_schedulers_lr_scheduler.h.html">Program Listing for File lr_scheduler.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_stable_macros.h.html">File macros.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_stable_macros.h.html">Program Listing for File macros.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_datasets_map.h.html">File map.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_datasets_map.h.html">Program Listing for File map.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_datasets_mnist.h.html">File mnist.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_datasets_mnist.h.html">Program Listing for File mnist.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nativert_ModelRunnerHandle.h.html">File ModelRunnerHandle.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nativert_ModelRunnerHandle.h.html">Program Listing for File ModelRunnerHandle.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_module.h.html">File module.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_module.h.html">Program Listing for File module.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_jit_api_module.h.html">File module.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_jit_api_module.h.html">Program Listing for File module.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_container_moduledict.h.html">File moduledict.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_container_moduledict.h.html">Program Listing for File moduledict.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_container_modulelist.h.html">File modulelist.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_container_modulelist.h.html">Program Listing for File modulelist.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules.h.html">File modules.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules.h.html">Program Listing for File modules.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_mps.h.html">File mps.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_mps.h.html">Program Listing for File mps.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_container_named_any.h.html">File named_any.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_container_named_any.h.html">Program Listing for File named_any.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nested.h.html">File nested.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nested.h.html">Program Listing for File nested.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn.h.html">File nn.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn.h.html">Program Listing for File nn.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_normalization.h.html">File normalization.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_normalization.h.html">Program Listing for File normalization.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_normalization.h.html">File normalization.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_normalization.h.html">Program Listing for File normalization.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_normalization.h.html">File normalization.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_normalization.h.html">Program Listing for File normalization.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_stable_ops.h.html">File ops.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_stable_ops.h.html">Program Listing for File ops.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_optim.h.html">File optim.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_optim.h.html">Program Listing for File optim.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_optim_optimizer.h.html">File optimizer.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_optim_optimizer.h.html">Program Listing for File optimizer.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_c10_util_Optional.h.html">File Optional.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_c10_util_Optional.h.html">Program Listing for File Optional.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_c10_util_OptionalArrayRef.h.html">File OptionalArrayRef.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_c10_util_OptionalArrayRef.h.html">Program Listing for File OptionalArrayRef.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options.h.html">File options.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options.h.html">Program Listing for File options.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_ordered_dict.h.html">File ordered_dict.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_ordered_dict.h.html">Program Listing for File ordered_dict.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_serialize_output-archive.h.html">File output-archive.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_serialize_output-archive.h.html">Program Listing for File output-archive.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_padding.h.html">File padding.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_padding.h.html">Program Listing for File padding.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_padding.h.html">File padding.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_padding.h.html">Program Listing for File padding.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_padding.h.html">File padding.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_padding.h.html">Program Listing for File padding.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_container_parameterdict.h.html">File parameterdict.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_container_parameterdict.h.html">Program Listing for File parameterdict.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_container_parameterlist.h.html">File parameterlist.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_container_parameterlist.h.html">Program Listing for File parameterlist.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_pimpl.h.html">File pimpl.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_pimpl.h.html">Program Listing for File pimpl.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_pixelshuffle.h.html">File pixelshuffle.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_pixelshuffle.h.html">Program Listing for File pixelshuffle.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_pixelshuffle.h.html">File pixelshuffle.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_pixelshuffle.h.html">Program Listing for File pixelshuffle.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_pixelshuffle.h.html">File pixelshuffle.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_pixelshuffle.h.html">Program Listing for File pixelshuffle.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_pooling.h.html">File pooling.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_pooling.h.html">Program Listing for File pooling.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_pooling.h.html">File pooling.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_pooling.h.html">Program Listing for File pooling.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_pooling.h.html">File pooling.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_pooling.h.html">Program Listing for File pooling.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_python.h.html">File python.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_python.h.html">Program Listing for File python.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_detail_queue.h.html">File queue.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_detail_queue.h.html">Program Listing for File queue.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_samplers_random.h.html">File random.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_samplers_random.h.html">Program Listing for File random.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_optim_schedulers_reduce_on_plateau_scheduler.h.html">File reduce_on_plateau_scheduler.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_optim_schedulers_reduce_on_plateau_scheduler.h.html">Program Listing for File reduce_on_plateau_scheduler.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_optim_rmsprop.h.html">File rmsprop.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_optim_rmsprop.h.html">Program Listing for File rmsprop.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_rnn.h.html">File rnn.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_rnn.h.html">Program Listing for File rnn.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_rnn.h.html">File rnn.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_rnn.h.html">Program Listing for File rnn.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_utils_rnn.h.html">File rnn.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_utils_rnn.h.html">Program Listing for File rnn.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_samplers.h.html">File samplers.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_samplers.h.html">Program Listing for File samplers.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_Scalar.h.html">File Scalar.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_Scalar.h.html">Program Listing for File Scalar.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_core_ScalarType.h.html">File ScalarType.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_core_ScalarType.h.html">Program Listing for File ScalarType.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_detail_sequencers.h.html">File sequencers.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_detail_sequencers.h.html">Program Listing for File sequencers.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_samplers_sequential.h.html">File sequential.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_samplers_sequential.h.html">Program Listing for File sequential.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_container_sequential.h.html">File sequential.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_container_sequential.h.html">Program Listing for File sequential.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_samplers_serialize.h.html">File serialize.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_samplers_serialize.h.html">Program Listing for File serialize.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_optim_serialize.h.html">File serialize.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_optim_serialize.h.html">Program Listing for File serialize.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_serialize.h.html">File serialize.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_serialize.h.html">Program Listing for File serialize.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_optim_sgd.h.html">File sgd.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_optim_sgd.h.html">Program Listing for File sgd.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_datasets_shared.h.html">File shared.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_datasets_shared.h.html">Program Listing for File shared.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_sparse.h.html">File sparse.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_sparse.h.html">Program Listing for File sparse.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_special.h.html">File special.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_special.h.html">Program Listing for File special.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_transforms_stack.h.html">File stack.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_transforms_stack.h.html">Program Listing for File stack.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_dataloader_stateful.h.html">File stateful.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_dataloader_stateful.h.html">Program Listing for File stateful.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_datasets_stateful.h.html">File stateful.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_datasets_stateful.h.html">Program Listing for File stateful.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_dataloader_stateless.h.html">File stateless.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_dataloader_stateless.h.html">Program Listing for File stateless.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_optim_schedulers_step_lr.h.html">File step_lr.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_optim_schedulers_step_lr.h.html">Program Listing for File step_lr.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_samplers_stream.h.html">File stream.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_samplers_stream.h.html">Program Listing for File stream.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_core_Tensor.h.html">File Tensor.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_core_Tensor.h.html">Program Listing for File Tensor.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_datasets_tensor.h.html">File tensor.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_datasets_tensor.h.html">Program Listing for File tensor.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_transforms_tensor.h.html">File tensor.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_transforms_tensor.h.html">Program Listing for File tensor.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_serialize_tensor.h.html">File tensor.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_serialize_tensor.h.html">Program Listing for File tensor.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_stable_tensor_struct.h.html">File tensor_struct.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_stable_tensor_struct.h.html">Program Listing for File tensor_struct.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_build_aten_src_ATen_core_TensorBody.h.html">File TensorBody.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_build_aten_src_ATen_core_TensorBody.h.html">Program Listing for File TensorBody.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_TensorOptions.h.html">File TensorOptions.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_TensorOptions.h.html">Program Listing for File TensorOptions.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_native_TensorShape.h.html">File TensorShape.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_native_TensorShape.h.html">Program Listing for File TensorShape.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_torch.h.html">File torch.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_torch.h.html">Program Listing for File torch.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_transformer.h.html">File transformer.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_transformer.h.html">Program Listing for File transformer.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_transformer.h.html">File transformer.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_transformer.h.html">Program Listing for File transformer.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_transformercoder.h.html">File transformercoder.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_transformercoder.h.html">Program Listing for File transformercoder.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_transformercoder.h.html">File transformercoder.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_transformercoder.h.html">Program Listing for File transformercoder.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_transformerlayer.h.html">File transformerlayer.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_transformerlayer.h.html">Program Listing for File transformerlayer.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_transformerlayer.h.html">File transformerlayer.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_transformerlayer.h.html">Program Listing for File transformerlayer.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_transforms.h.html">File transforms.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_transforms.h.html">Program Listing for File transforms.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_cudnn_Types.h.html">File Types.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_cudnn_Types.h.html">Program Listing for File Types.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_types.h.html">File types.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_types.h.html">Program Listing for File types.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_upsampling.h.html">File upsampling.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_upsampling.h.html">Program Listing for File upsampling.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_upsampling.h.html">File upsampling.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_upsampling.h.html">Program Listing for File upsampling.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_upsampling.h.html">File upsampling.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_upsampling.h.html">Program Listing for File upsampling.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_aten_src_ATen_cudnn_Utils.h.html">File Utils.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_aten_src_ATen_cudnn_Utils.h.html">Program Listing for File Utils.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_modules_utils.h.html">File utils.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_modules_utils.h.html">Program Listing for File utils.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_utils.h.html">File utils.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_utils.h.html">Program Listing for File utils.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_utils.h.html">File utils.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_utils.h.html">Program Listing for File utils.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_autograd_variable.h.html">File variable.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_autograd_variable.h.html">Program Listing for File variable.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_autograd_generated_variable_factories.h.html">File variable_factories.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_autograd_generated_variable_factories.h.html">Program Listing for File variable_factories.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_version.h.html">File version.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_version.h.html">Program Listing for File version.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_functional_vision.h.html">File vision.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_functional_vision.h.html">Program Listing for File vision.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_nn_options_vision.h.html">File vision.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_nn_options_vision.h.html">Program Listing for File vision.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_data_worker_exception.h.html">File worker_exception.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_data_worker_exception.h.html">Program Listing for File worker_exception.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_torch_csrc_api_include_torch_xpu.h.html">File xpu.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_torch_csrc_api_include_torch_xpu.h.html">Program Listing for File xpu.h</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="file_c10_xpu_XPUStream.h.html">File XPUStream.h</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="program_listing_file_c10_xpu_XPUStream.h.html">Program Listing for File XPUStream.h</a></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="library_root.html" class="nav-link">Library API</a></li>
    
    
    <li class="breadcrumb-item"><a href="file_torch_csrc_autograd_function.h.html" class="nav-link">File function.h</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Program...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5"></span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="library_root.html">
        <meta itemprop="name" content="Library API">
        <meta itemprop="position" content="1">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="file_torch_csrc_autograd_function.h.html">
        <meta itemprop="name" content="File function.h">
        <meta itemprop="position" content="2">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="Program Listing for File function.h">
        <meta itemprop="position" content="3">
      </div>
    </div>

    
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="program-listing-for-file-function-h">
<span id="program-listing-file-torch-csrc-autograd-function-h"></span><h1>Program Listing for File function.h<a class="headerlink" href="#program-listing-for-file-function-h" title="Link to this heading">#</a></h1>
<p> <a class="reference internal" href="file_torch_csrc_autograd_function.h.html#file-torch-csrc-autograd-function-h"><span class="std std-ref">Return to documentation for file</span></a> (<code class="docutils literal notranslate"><span class="pre">torch/csrc/autograd/function.h</span></code>)</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma once</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/csrc/autograd/anomaly_mode.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/csrc/autograd/edge.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/csrc/autograd/grad_mode.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/csrc/autograd/graph_task.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/csrc/autograd/input_metadata.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/csrc/autograd/saved_variable.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/csrc/autograd/variable.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/csrc/utils/python_stub.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/csrc/utils/variadic.h&gt;</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;ATen/SequenceNumber.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;ATen/core/Tensor.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;ATen/record_function.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/util/Exception.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/util/irange.h&gt;</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;algorithm&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdint&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;initializer_list&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;memory&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;string&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;utility&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">torch</span><span class="o">::</span><span class="nn">autograd</span><span class="w"> </span><span class="p">{</span>

<span class="k">struct</span><span class="w"> </span><span class="nc">Edge</span><span class="p">;</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">FunctionPostHook</span><span class="p">;</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">FunctionPreHook</span><span class="p">;</span>

<span class="k">using</span><span class="w"> </span><span class="n">tensor_list</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="n">variable_list</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Variable</span><span class="o">&gt;</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="n">edge_list</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Edge</span><span class="o">&gt;</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="n">saved_variable_list</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">SavedVariable</span><span class="o">&gt;</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="n">ivalue_list</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">IValue</span><span class="o">&gt;</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="n">functional_apply_t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">function</span><span class="o">&lt;</span>
<span class="w">    </span><span class="n">variable_list</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">variable_list</span><span class="o">&amp;</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">IValue</span><span class="o">&gt;&amp;</span><span class="p">)</span><span class="o">&gt;</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="n">IndexRange</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="p">,</span><span class="w"> </span><span class="kt">size_t</span><span class="o">&gt;</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">dynamo</span><span class="o">::</span><span class="n">autograd</span><span class="o">::</span><span class="n">CompiledNodeArgs</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">dynamo</span><span class="o">::</span><span class="n">autograd</span><span class="o">::</span><span class="n">PackedArgs</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">dynamo</span><span class="o">::</span><span class="n">autograd</span><span class="o">::</span><span class="n">SwapSavedVariables</span><span class="p">;</span>

<span class="c1">// Custom deleter to prevent stack overflows.</span>
<span class="n">TORCH_API</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">deleteNode</span><span class="p">(</span><span class="n">Node</span><span class="o">*</span><span class="w"> </span><span class="n">function</span><span class="p">);</span>

<span class="c1">// Guard that sets and restores the evaluating node</span>
<span class="k">class</span><span class="w"> </span><span class="nc">NodeGuard</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="k">explicit</span><span class="w"> </span><span class="n">NodeGuard</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">Node</span><span class="o">&gt;</span><span class="w"> </span><span class="n">node</span><span class="p">);</span>
<span class="w">  </span><span class="o">~</span><span class="n">NodeGuard</span><span class="p">();</span>

<span class="w"> </span><span class="k">private</span><span class="o">:</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">Node</span><span class="o">&gt;</span><span class="w"> </span><span class="n">last_evaluating_node_</span><span class="p">;</span>
<span class="p">};</span>

<span class="c1">// Return the Node currently being evaluated (if any)</span>
<span class="c1">// This is only set during the backward pass while a Node is being</span>
<span class="c1">// executed.</span>
<span class="n">TORCH_API</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">Node</span><span class="o">&gt;</span><span class="w"> </span><span class="n">get_current_node</span><span class="p">();</span>

<span class="c1">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="c1">//                               Node</span>
<span class="c1">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="c1">// A `Node` is an abstract class that represents an operation taking zero</span>
<span class="c1">// or more input `Variable`s and producing zero or more output `Variable`s. All</span>
<span class="c1">// functions in PyTorch&#39;s autograd machinery derive from this class and</span>
<span class="c1">// override its `apply` method. Instances of such subclasses will then be</span>
<span class="c1">// invocable via the call operator.</span>
<span class="c1">//</span>
<span class="c1">//                    Nodes in the Autograd Graph</span>
<span class="c1">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="c1">// When viewing the autograd system as a graph, `Node`s are the vertices or</span>
<span class="c1">// nodes, connected to each other via (directed) `Edge`s, which themselves are</span>
<span class="c1">// represented via (`Node`, input_nr) pairs. `Variable`s are the outputs to</span>
<span class="c1">// and inputs of `Node`s, and travel between these edges during execution</span>
<span class="c1">// of the graph. When two or more `Edge`s (from different sources) point at the</span>
<span class="c1">// same input to a `Node`, the values produced along all of these edges are</span>
<span class="c1">// implicitly summed prior to being forwarded to the target `Node`.</span>
<span class="c1">//</span>
<span class="c1">//                              Hierarchy</span>
<span class="c1">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="c1">// Subclasses usually represent differentiable functions as well as their</span>
<span class="c1">// gradient operators. Note, however, that due to the very general definition</span>
<span class="c1">// of a `Node` taking *zero* or more inputs and producing *zero* or more</span>
<span class="c1">// outputs, uses of `Node`s are flexible and extend beyond purely</span>
<span class="c1">// mathematical operations. For example, the `AccumulateGrad` function is a</span>
<span class="c1">// *sink*: it takes one input, but produces no outputs, instead accumulating</span>
<span class="c1">// the input as a side effect. At the other extreme, the `GraphRoot` function</span>
<span class="c1">// receives no inputs from other functions, but produces multiple outputs.</span>
<span class="c1">//</span>
<span class="c1">//                              Interface</span>
<span class="c1">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="c1">// The most important method on `Node` is the call operator, which takes in</span>
<span class="c1">// a list of variables and produces a list of variables. The precise size of</span>
<span class="c1">// these lists can be determined with `num_inputs()` and `num_outputs()`.</span>
<span class="c1">// `Node`s are stitched together via their `next_edge` interface, which let</span>
<span class="c1">// you manipulate the set of outgoing edges of a `Node`. You can add an</span>
<span class="c1">// edge with `add_next_edge()`, retrieve an edge with `next_edge(index)` and</span>
<span class="c1">// iterate over them via the `next_edges()` method. Other methods exist for</span>
<span class="c1">// integration with the JIT and other parts of PyTorch. Every `Node` has a</span>
<span class="c1">// *sequence number* that increases monotonically in the order of `Node`</span>
<span class="c1">// construction. It can be retrieved via the `sequence_nr()` method. Note that</span>
<span class="c1">// this sequence number is *thread local*. This means that when `Node`s</span>
<span class="c1">// `A`, `B` and `C` are created consecutively in the same thread, their</span>
<span class="c1">// sequence numbers will be ordered `A` &lt; `B` &lt; `C`. If, however, `A` and `B`</span>
<span class="c1">// are created in one thread and `C` is created in a new thread, there are *no</span>
<span class="c1">// guarantees* w.r.t. the ordering of `C` relative to `A` or `B`.</span>
<span class="c1">// See NOTE [ Sequence Number] for more details on the usages of sequence</span>
<span class="c1">// number.</span>
<span class="c1">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">TORCH_API</span><span class="w"> </span><span class="n">Node</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">enable_shared_from_this</span><span class="o">&lt;</span><span class="n">Node</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="k">explicit</span><span class="w"> </span><span class="n">Node</span><span class="p">(</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">sequence_nr</span><span class="p">,</span><span class="w"> </span><span class="n">edge_list</span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">next_edges</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">edge_list</span><span class="p">())</span>
<span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">sequence_nr_</span><span class="p">(</span><span class="n">sequence_nr</span><span class="p">),</span><span class="w"> </span><span class="n">next_edges_</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">next_edges</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Edge</span><span class="o">&amp;</span><span class="w"> </span><span class="n">edge</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">next_edges_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">update_topological_nr</span><span class="p">(</span><span class="n">edge</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">AnomalyMode</span><span class="o">::</span><span class="n">is_enabled</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">metadata</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">store_stack</span><span class="p">();</span>

<span class="w">      </span><span class="c1">// If anomaly mode is enabled and graph is constructed, then assign the</span>
<span class="w">      </span><span class="c1">// currently evaluating node as the parent of this node.</span>
<span class="w">      </span><span class="c1">// A parent is a Node where this Node is created.</span>
<span class="w">      </span><span class="c1">// We are tracking the parents to track multiple backward operations.</span>
<span class="w">      </span><span class="n">assign_parent</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Store the thread_id of the forward operator.</span>
<span class="w">    </span><span class="c1">// See NOTE [ Sequence Numbers ]</span>
<span class="w">    </span><span class="n">thread_id_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">RecordFunction</span><span class="o">::</span><span class="n">currentThreadId</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">explicit</span><span class="w"> </span><span class="n">Node</span><span class="p">(</span><span class="n">edge_list</span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">next_edges</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">edge_list</span><span class="p">())</span>
<span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">Node</span><span class="p">(</span>
<span class="w">            </span><span class="cm">/*sequence_nr=*/</span><span class="n">at</span><span class="o">::</span><span class="n">sequence_number</span><span class="o">::</span><span class="n">get_and_increment</span><span class="p">(),</span>
<span class="w">            </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">next_edges</span><span class="p">))</span><span class="w"> </span><span class="p">{}</span>

<span class="w">  </span><span class="n">Node</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Node</span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">delete</span><span class="p">;</span>
<span class="w">  </span><span class="n">Node</span><span class="p">(</span><span class="n">Node</span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">delete</span><span class="p">;</span>
<span class="w">  </span><span class="n">Node</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Node</span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">delete</span><span class="p">;</span>
<span class="w">  </span><span class="n">Node</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">=</span><span class="p">(</span><span class="n">Node</span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">delete</span><span class="p">;</span>
<span class="w">  </span><span class="k">virtual</span><span class="w"> </span><span class="o">~</span><span class="n">Node</span><span class="p">()</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">Node</span><span class="o">&gt;</span><span class="w"> </span><span class="n">getptr</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">shared_from_this</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">variable_list</span><span class="w"> </span><span class="k">operator</span><span class="p">()(</span><span class="n">variable_list</span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">inputs</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// In the first iteration of named tensors, autograd ignores names and</span>
<span class="w">    </span><span class="c1">// operates on unnamed tensors. In the long term, autograd should</span>
<span class="w">    </span><span class="c1">// probably operate with names.</span>
<span class="w">    </span><span class="n">at</span><span class="o">::</span><span class="n">NoNamesGuard</span><span class="w"> </span><span class="n">no_names_guard</span><span class="p">;</span>

<span class="cp">#ifdef USE_ROCM</span>
<span class="w">    </span><span class="c1">// Keep track of backward pass for rocblas.</span>
<span class="w">    </span><span class="n">at</span><span class="o">::</span><span class="n">ROCmBackwardPassGuard</span><span class="w"> </span><span class="n">in_backward</span><span class="p">;</span>
<span class="cp">#endif</span>

<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">step_callbacks</span><span class="w"> </span><span class="o">=</span>
<span class="w">        </span><span class="n">at</span><span class="o">::</span><span class="n">getStepCallbacksUnlessEmpty</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">RecordScope</span><span class="o">::</span><span class="n">BACKWARD_FUNCTION</span><span class="p">);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">C10_UNLIKELY</span><span class="p">(</span><span class="n">step_callbacks</span><span class="p">.</span><span class="n">has_value</span><span class="p">()))</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">at</span><span class="o">::</span><span class="n">RecordFunction</span><span class="w"> </span><span class="nf">guard</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="o">*</span><span class="n">step_callbacks</span><span class="p">));</span>
<span class="w">      </span><span class="c1">// Using sequence number and thread id to correlate with</span>
<span class="w">      </span><span class="c1">// the forward pass function</span>
<span class="w">      </span><span class="n">guard</span><span class="p">.</span><span class="n">setForwardThreadId</span><span class="p">(</span><span class="n">thread_id_</span><span class="p">);</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">guard</span><span class="p">.</span><span class="n">needsInputs</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">IValue</span><span class="o">&gt;</span><span class="w"> </span><span class="n">inputs_vec</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">inputs</span><span class="p">.</span><span class="n">end</span><span class="p">());</span>
<span class="w">        </span><span class="n">guard</span><span class="p">.</span><span class="n">before</span><span class="p">(</span>
<span class="w">            </span><span class="n">name</span><span class="p">(),</span>
<span class="w">            </span><span class="n">c10</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">IValue</span><span class="o">&gt;</span><span class="p">(</span>
<span class="w">                </span><span class="n">inputs_vec</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">inputs_vec</span><span class="p">.</span><span class="n">size</span><span class="p">()),</span>
<span class="w">            </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sequence_nr</span><span class="p">()));</span>
<span class="w">      </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">guard</span><span class="p">.</span><span class="n">before</span><span class="p">(</span><span class="n">name</span><span class="p">(),</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sequence_nr</span><span class="p">()));</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">apply</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">inputs</span><span class="p">));</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">apply</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">inputs</span><span class="p">));</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Graph Connectivity API</span>
<span class="w">  </span><span class="c1">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>

<span class="w">  </span><span class="c1">// Inputs. NOTE: inputs of the grad_fn correspond to Tensor outputs of the</span>
<span class="w">  </span><span class="c1">// forward function.</span>

<span class="w">  </span><span class="c1">// Marker for expected undefined input</span>
<span class="w">  </span><span class="k">struct</span><span class="w"> </span><span class="nc">undefined_input</span><span class="w"> </span><span class="p">{};</span>

<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="nf">add_input_metadata</span><span class="p">(</span>
<span class="w">      </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="o">&amp;</span><span class="w"> </span><span class="n">options</span><span class="p">,</span>
<span class="w">      </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">shape</span><span class="p">,</span>
<span class="w">      </span><span class="kt">bool</span><span class="w"> </span><span class="n">is_tensor_subclass</span><span class="p">,</span>
<span class="w">      </span><span class="kt">bool</span><span class="w"> </span><span class="n">is_nested</span><span class="p">,</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">grad_dtype</span><span class="p">)</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">input_nr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input_metadata_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">meta_shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MetadataShape</span><span class="p">{</span><span class="n">std</span><span class="o">::</span><span class="n">in_place_type</span><span class="o">&lt;</span><span class="n">SymIntSmallVec</span><span class="o">&gt;</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="p">};</span>
<span class="w">    </span><span class="n">input_metadata_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span>
<span class="w">        </span><span class="n">options</span><span class="p">,</span><span class="w"> </span><span class="n">meta_shape</span><span class="p">,</span><span class="w"> </span><span class="n">is_tensor_subclass</span><span class="p">,</span><span class="w"> </span><span class="n">is_nested</span><span class="p">,</span><span class="w"> </span><span class="n">grad_dtype</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">input_nr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="nf">add_input_metadata</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">t</span><span class="p">)</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">input_nr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input_metadata_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
<span class="w">    </span><span class="n">input_metadata_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">t</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">input_nr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="nf">add_input_metadata</span><span class="p">(</span><span class="n">undefined_input</span><span class="w"> </span><span class="n">u</span><span class="p">)</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">input_nr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input_metadata_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
<span class="w">    </span><span class="n">input_metadata_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">();</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">input_nr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="nf">num_inputs</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">input_metadata_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">InputMetadata</span><span class="o">&amp;</span><span class="w"> </span><span class="nf">input_metadata</span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">input_metadata_</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Danger: not thread safe, caller must protect with lock</span>
<span class="w">  </span><span class="n">InputMetadata</span><span class="o">&amp;</span><span class="w"> </span><span class="nf">mutable_input_metadata</span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">input_metadata_</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">Stream</span><span class="o">&gt;</span><span class="w"> </span><span class="n">stream</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">opt_device_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">getAccelerator</span><span class="p">();</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">opt_device_type</span><span class="p">.</span><span class="n">has_value</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="n">metadata</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">input_metadata_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">metadata</span><span class="p">.</span><span class="n">device</span><span class="p">().</span><span class="n">type</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">opt_device_type</span><span class="p">.</span><span class="n">value</span><span class="p">())</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">metadata</span><span class="p">.</span><span class="n">stream</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Used by the engine to determine what device thread to run on</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">device</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Since we pick the first non-CPU tensor, this won&#39;t work with</span>
<span class="w">    </span><span class="c1">// mixed device-type operations (e.g., an op that is both CUDA</span>
<span class="w">    </span><span class="c1">// and XLA).  This is *incredibly* unlikely, so we don&#39;t worry</span>
<span class="w">    </span><span class="c1">// about it.</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="n">metadata</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">input_metadata_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">auto</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">metadata</span><span class="p">.</span><span class="n">device</span><span class="p">();</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">device</span><span class="p">.</span><span class="n">type</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">kCPU</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">device</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="c1">// Only report to the CPU thread if there really were no tensors</span>
<span class="w">    </span><span class="c1">// from other devices.</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">kCPU</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">clear_input_metadata</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">input_metadata_</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Outputs (&quot;Next Edges&quot;)</span>

<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">update_topological_nr</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Edge</span><span class="o">&amp;</span><span class="w"> </span><span class="n">edge</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">TORCH_INTERNAL_ASSERT</span><span class="p">(</span>
<span class="w">        </span><span class="o">!</span><span class="n">has_parent_</span><span class="p">,</span>
<span class="w">        </span><span class="s">&quot;Cannot update a node&#39;s topological_nr after it already has a parent.&quot;</span>
<span class="w">        </span><span class="s">&quot; If we allow this, we can no longer guarantee that a parent&#39;s&quot;</span>
<span class="w">        </span><span class="s">&quot; topo_nr is always greater than those of all its children&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="n">Node</span><span class="o">*</span><span class="w"> </span><span class="n">node</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">edge</span><span class="p">.</span><span class="n">function</span><span class="p">.</span><span class="n">get</span><span class="p">();</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">node</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">auto</span><span class="w"> </span><span class="n">topo_nr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">node</span><span class="o">-&gt;</span><span class="n">topological_nr</span><span class="p">();</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">topological_nr_</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">topo_nr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">topological_nr_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">topo_nr</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">set_next_edge</span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">Edge</span><span class="w"> </span><span class="n">edge</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">update_topological_nr</span><span class="p">(</span><span class="n">edge</span><span class="p">);</span>
<span class="w">    </span><span class="n">next_edges_</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">edge</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">add_next_edge</span><span class="p">(</span><span class="n">Edge</span><span class="w"> </span><span class="n">edge</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">update_topological_nr</span><span class="p">(</span><span class="n">edge</span><span class="p">);</span>
<span class="w">    </span><span class="n">next_edges_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">edge</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">set_next_edges</span><span class="p">(</span><span class="n">edge_list</span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">next_edges</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">next_edges_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">next_edges</span><span class="p">);</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="n">next_edge</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">next_edges_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">update_topological_nr</span><span class="p">(</span><span class="n">next_edge</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">Edge</span><span class="o">&amp;</span><span class="w"> </span><span class="n">next_edge</span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">next_edges_</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">edge_list</span><span class="o">&amp;</span><span class="w"> </span><span class="n">next_edges</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">next_edges_</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">edge_list</span><span class="o">&amp;</span><span class="w"> </span><span class="n">next_edges</span><span class="p">()</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">next_edges_</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">num_outputs</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">next_edges_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Miscellaneous Methods</span>
<span class="w">  </span><span class="c1">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>

<span class="w">  </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">sequence_nr</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">sequence_nr_</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">set_sequence_nr</span><span class="p">(</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">sequence_nr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">sequence_nr_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sequence_nr</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// NOTE [ Topological Number ]</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">// topological_nr is used to prune branches in the DAG during autograd</span>
<span class="w">  </span><span class="c1">// discovery as maintaining topological_nr helps us check in O(1) if there</span>
<span class="w">  </span><span class="c1">// does NOT exist a directed path between two nodes.</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">// The topological order number of this `Node` representing the length of the</span>
<span class="w">  </span><span class="c1">// longest possible path from this Node to any leaf node. If you are leaf</span>
<span class="w">  </span><span class="c1">// node, aka AccumulateGrad, this will be zero. This value has the property</span>
<span class="w">  </span><span class="c1">// that For every pair of nodes X, Y in G, existence of a directed path from X</span>
<span class="w">  </span><span class="c1">// to Y implies topo_nr(X) &gt; topo_nr(Y). The converse is not true, however, so</span>
<span class="w">  </span><span class="c1">// we cannot prove existence of a path from X to Y, only non-existence.</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">// One assumption we make when using topo_nr is that once a node</span>
<span class="w">  </span><span class="c1">// has been used, i.e., has a parent node, its own topo_nr does not change</span>
<span class="w">  </span><span class="c1">// we have added some checks with the `has_parent_` field to enforce this.</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">// What NOT to do:</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">//   1) 2 -&gt; 1 -&gt; 0               In this diagram we label nodes with their</span>
<span class="w">  </span><span class="c1">//   topo_nr.</span>
<span class="w">  </span><span class="c1">//      2 -&gt; 1 -&gt; 0               We have two simple graphs that can each</span>
<span class="w">  </span><span class="c1">//      arise from</span>
<span class="w">  </span><span class="c1">//                                `t.exp().exp()`, for example.</span>
<span class="w">  </span><span class="c1">//   2)        2 -&gt; 1 -&gt; 0</span>
<span class="w">  </span><span class="c1">//            /</span>
<span class="w">  </span><span class="c1">//      2 -&gt; 1 -&gt; 0               We add 2 as a next edge to 1 even though 1</span>
<span class="w">  </span><span class="c1">//      already</span>
<span class="w">  </span><span class="c1">//                                has a parent.</span>
<span class="w">  </span><span class="c1">//   3)        2 -&gt; 1 -&gt; 0</span>
<span class="w">  </span><span class="c1">//            /</span>
<span class="w">  </span><span class="c1">//      2 -&gt; 3 -&gt; 0               2 &lt; 3, yet there exists a path from 2 to 3!</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">topological_nr</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">has_parent_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">topological_nr_</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// assigning a node as a parent to this node</span>
<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">assign_parent</span><span class="p">();</span>

<span class="w">  </span><span class="kt">uint64_t</span><span class="w"> </span><span class="nf">thread_id</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">thread_id_</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">virtual</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="nf">name</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>

<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">should_compute_output</span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">output_edge_index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">TORCH_CHECK</span><span class="p">(</span><span class="n">output_edge_index</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_outputs</span><span class="p">(),</span><span class="w"> </span><span class="s">&quot;Index out of range&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">next_edges_</span><span class="p">[</span><span class="n">output_edge_index</span><span class="p">].</span><span class="n">is_valid</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">should_compute_output</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">initializer_list</span><span class="o">&lt;</span><span class="n">IndexRange</span><span class="o">&gt;</span><span class="w"> </span><span class="n">idxs</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">any_of</span><span class="p">(</span><span class="n">idxs</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">idxs</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="w"> </span><span class="p">[</span><span class="k">this</span><span class="p">](</span><span class="n">IndexRange</span><span class="w"> </span><span class="n">range</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">irange</span><span class="p">(</span><span class="n">range</span><span class="p">.</span><span class="n">first</span><span class="p">,</span><span class="w"> </span><span class="n">range</span><span class="p">.</span><span class="n">second</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">should_compute_output</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
<span class="w">          </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">    </span><span class="p">});</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">task_should_compute_output</span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">output_edge_index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">TORCH_CHECK</span><span class="p">(</span><span class="n">output_edge_index</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_outputs</span><span class="p">(),</span><span class="w"> </span><span class="s">&quot;Index out of range&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="n">next</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">next_edges_</span><span class="p">[</span><span class="n">output_edge_index</span><span class="p">];</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">next</span><span class="p">.</span><span class="n">is_valid</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">exec_info</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_current_graph_task_exec_info</span><span class="p">();</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">exec_info</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="o">!</span><span class="n">exec_info</span><span class="o">-&gt;</span><span class="n">empty</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">exec_info</span><span class="o">-&gt;</span><span class="n">find</span><span class="p">(</span><span class="n">next</span><span class="p">.</span><span class="n">function</span><span class="p">.</span><span class="n">get</span><span class="p">());</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">it</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">exec_info</span><span class="o">-&gt;</span><span class="n">end</span><span class="p">()</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="o">!</span><span class="n">it</span><span class="o">-&gt;</span><span class="n">second</span><span class="p">.</span><span class="n">should_execute</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">          </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span><span class="w"> </span><span class="c1">// this edge is not needed for the current graph_task</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">task_should_compute_output</span><span class="p">(</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">initializer_list</span><span class="o">&lt;</span><span class="n">IndexRange</span><span class="o">&gt;</span><span class="w"> </span><span class="n">idxs</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">any_of</span><span class="p">(</span><span class="n">idxs</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">idxs</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="w"> </span><span class="p">[</span><span class="k">this</span><span class="p">](</span><span class="n">IndexRange</span><span class="w"> </span><span class="n">range</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">irange</span><span class="p">(</span><span class="n">range</span><span class="p">.</span><span class="n">first</span><span class="p">,</span><span class="w"> </span><span class="n">range</span><span class="p">.</span><span class="n">second</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">task_should_compute_output</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
<span class="w">          </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">    </span><span class="p">});</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">PyObject</span><span class="o">*</span><span class="w"> </span><span class="nf">pyobj</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">pyobj_</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="nf">set_pyobj</span><span class="p">(</span><span class="n">PyObject</span><span class="o">*</span><span class="w"> </span><span class="n">pyobj</span><span class="p">)</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">pyobj_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pyobj</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">AnomalyMetadata</span><span class="o">*</span><span class="w"> </span><span class="nf">metadata</span><span class="p">()</span><span class="w"> </span><span class="k">noexcept</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Hook API</span>
<span class="w">  </span><span class="c1">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>

<span class="w">  </span><span class="kt">uintptr_t</span><span class="w"> </span><span class="nf">add_post_hook</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">FunctionPostHook</span><span class="o">&gt;&amp;&amp;</span><span class="w"> </span><span class="n">post_hook</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">post_hooks_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">post_hook</span><span class="p">));</span>
<span class="w">    </span><span class="c1">// Use the raw pointer as the unique key to identify this hook. This key</span>
<span class="w">    </span><span class="c1">// can then be used in del_post_hook(key) to remove this hook.</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="kt">uintptr_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">post_hooks_</span><span class="p">.</span><span class="n">back</span><span class="p">().</span><span class="n">get</span><span class="p">());</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">FunctionPostHook</span><span class="o">&gt;&gt;&amp;</span><span class="w"> </span><span class="n">post_hooks</span><span class="p">()</span>
<span class="w">      </span><span class="k">const</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">post_hooks_</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// delete a post hook matching the key</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">del_post_hook</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">uintptr_t</span><span class="o">&amp;</span><span class="w"> </span><span class="n">key</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">post_hooks_</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">post_hooks_</span><span class="p">.</span><span class="n">end</span><span class="p">();</span><span class="w"> </span><span class="o">++</span><span class="n">it</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">key</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="kt">uintptr_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">it</span><span class="o">-&gt;</span><span class="n">get</span><span class="p">()))</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">post_hooks_</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">it</span><span class="p">);</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">FunctionPostHook</span><span class="o">&gt;&gt;&amp;</span><span class="w"> </span><span class="n">post_hooks</span><span class="p">()</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">post_hooks_</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">add_pre_hook</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">FunctionPreHook</span><span class="o">&gt;&amp;&amp;</span><span class="w"> </span><span class="n">pre_hook</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">pre_hooks_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">pre_hook</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">add_tensor_pre_hook</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">FunctionPreHook</span><span class="o">&gt;&amp;&amp;</span><span class="w"> </span><span class="n">pre_hook</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">tensor_pre_hooks_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">pre_hook</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">add_retains_grad_hook</span><span class="p">(</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">FunctionPreHook</span><span class="o">&gt;&amp;&amp;</span><span class="w"> </span><span class="n">pre_hook</span><span class="p">,</span>
<span class="w">      </span><span class="kt">size_t</span><span class="w"> </span><span class="n">output_idx</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">retains_grad_hooks_</span><span class="p">[</span><span class="n">output_idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">pre_hook</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">FunctionPreHook</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pop_retains_grad_hook</span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">output_idx</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">retains_grad_hooks_</span><span class="p">[</span><span class="n">output_idx</span><span class="p">]);</span>
<span class="w">    </span><span class="n">retains_grad_hooks_</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">output_idx</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">ret</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">FunctionPreHook</span><span class="o">&gt;&gt;&amp;</span><span class="w"> </span><span class="n">pre_hooks</span><span class="p">()</span>
<span class="w">      </span><span class="k">const</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">pre_hooks_</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">FunctionPreHook</span><span class="o">&gt;&gt;&amp;</span><span class="w"> </span><span class="n">pre_hooks</span><span class="p">()</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">pre_hooks_</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">virtual</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">FunctionPreHook</span><span class="o">&gt;&gt;&amp;</span>
<span class="w">  </span><span class="n">tensor_pre_hooks</span><span class="p">()</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">tensor_pre_hooks_</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">virtual</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">PostAccumulateGradHook</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">tensor_post_acc_grad_hooks</span><span class="p">()</span>
<span class="w">      </span><span class="k">const</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">PostAccumulateGradHook</span><span class="o">&gt;</span><span class="w"> </span><span class="n">empty</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">empty</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">unordered_map</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">FunctionPreHook</span><span class="o">&gt;&gt;&amp;</span>
<span class="w">  </span><span class="n">retains_grad_hooks</span><span class="p">()</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">retains_grad_hooks_</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Customization Points for Subclasses</span>
<span class="w">  </span><span class="c1">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>

<span class="w">  </span><span class="k">virtual</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">release_variables</span><span class="p">()</span><span class="w"> </span><span class="p">{}</span>

<span class="w">  </span><span class="k">virtual</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">will_release_variables</span><span class="p">()</span><span class="w"> </span><span class="p">{}</span>

<span class="w">  </span><span class="k">virtual</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">is_traceable</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">virtual</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">passes_state_transparently</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// see [Note: Compiled Autograd]</span>
<span class="w">  </span><span class="c1">// Used by compiled autograd to</span>
<span class="w">  </span><span class="c1">//   1) Extract tensors/symint args</span>
<span class="w">  </span><span class="c1">//   2) Collect node information for specialization and caching</span>
<span class="w">  </span><span class="c1">// Implementations in subclasses should call args.collect() with all node</span>
<span class="w">  </span><span class="c1">// attrs. These functions are only called during backward.</span>
<span class="w">  </span><span class="k">virtual</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">compiled_args</span><span class="p">(</span><span class="n">CompiledNodeArgs</span><span class="o">&amp;</span><span class="w"> </span><span class="n">args</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">TORCH_CHECK_NOT_IMPLEMENTED</span><span class="p">(</span>
<span class="w">        </span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="s">&quot;compiled_args not implemented: &quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">name</span><span class="p">());</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Used by compiled autograd to call apply() with different saved tensors</span>
<span class="w">  </span><span class="c1">// Implementations should call saved.before() on all attrs, then apply(), then</span>
<span class="w">  </span><span class="c1">// saved.after() on all attrs in the same order.</span>
<span class="w">  </span><span class="k">virtual</span><span class="w"> </span><span class="n">variable_list</span><span class="w"> </span><span class="n">apply_with_saved</span><span class="p">(</span>
<span class="w">      </span><span class="k">const</span><span class="w"> </span><span class="n">variable_list</span><span class="o">&amp;</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span>
<span class="w">      </span><span class="n">SwapSavedVariables</span><span class="o">&amp;</span><span class="w"> </span><span class="n">saved</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">TORCH_CHECK_NOT_IMPLEMENTED</span><span class="p">(</span>
<span class="w">        </span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="s">&quot;apply_with_saved not implemented: &quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">name</span><span class="p">());</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// If this node is the AOTBackward node produced by torch.compile.</span>
<span class="w">  </span><span class="c1">// Compiled Autograd special-cases on this information.</span>
<span class="w">  </span><span class="k">virtual</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">is_aot_backward</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w"> </span><span class="k">protected</span><span class="o">:</span>
<span class="w">  </span><span class="k">virtual</span><span class="w"> </span><span class="n">variable_list</span><span class="w"> </span><span class="n">apply</span><span class="p">(</span><span class="n">variable_list</span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">inputs</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">  </span><span class="n">variable_list</span><span class="w"> </span><span class="nf">traced_apply</span><span class="p">(</span><span class="n">variable_list</span><span class="w"> </span><span class="n">inputs</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Sequence number used to correlate backward nodes with forward ops in the</span>
<span class="w">  </span><span class="c1">// profiler and provide determinism in the engine.</span>
<span class="w">  </span><span class="c1">// NOLINTNEXTLINE(cppcoreguidelines-avoid-const-or-ref-data-members)</span>
<span class="w">  </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">sequence_nr_</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// See NOTE [ Topological Number ]</span>
<span class="w">  </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">topological_nr_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Tracks whether this node has been added as the next_edge of another node</span>
<span class="w">  </span><span class="c1">// via set_next_edge(s), which always calls topological_nr() of all its</span>
<span class="w">  </span><span class="c1">// children See NOTE [ Topological Number ] for why we need this.</span>
<span class="w">  </span><span class="k">mutable</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">has_parent_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Id of the thread that created the instance</span>
<span class="w">  </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">thread_id_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Note [Thread Safety on Autograd Node]</span>
<span class="w">  </span><span class="c1">// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="w">  </span><span class="c1">// Autograd Engine let the owning thread which calls Engine::execute to drive</span>
<span class="w">  </span><span class="c1">// the GraphTask execution, there might be cases that part of the GraphTask is</span>
<span class="w">  </span><span class="c1">// shared across different `backward()` or `grad()` calls, i.e. fork new</span>
<span class="w">  </span><span class="c1">// threads in the middle of the forward and call `backward()` separately from</span>
<span class="w">  </span><span class="c1">// different threads. We need to protect the thread safety on NodeTask to</span>
<span class="w">  </span><span class="c1">// prevent data racing on shared variables read/write.</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">// NB: This is only needed for Autograd Nodes that runs on CPU, technically</span>
<span class="w">  </span><span class="c1">// &quot;CUDA&quot;, &quot;XLA&quot; nodes don&#39;t need locking because device threads are always</span>
<span class="w">  </span><span class="c1">// single threaded.</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">// Here we add a thread mutex to help protect the Node&#39;s thread safety, so</span>
<span class="w">  </span><span class="c1">// that different threads cannot race the shared data when executing the same</span>
<span class="w">  </span><span class="c1">// NodeTask from multiple CPU threads. It IS the user/developer responsibility</span>
<span class="w">  </span><span class="c1">// to take advantage of this mutex to protect the thread safety of their</span>
<span class="w">  </span><span class="c1">// autograd Node. The general strategy of thread safety on autograd Node:</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">// 1. User should lock the mutex during Node::release_variables() if the Node</span>
<span class="w">  </span><span class="c1">// needs</span>
<span class="w">  </span><span class="c1">//    to release the variables on the fly, this serve the purpose that when we</span>
<span class="w">  </span><span class="c1">//    release saved_variables from one thread, no other threads can release</span>
<span class="w">  </span><span class="c1">//    the saved variables concurrently. call the Node::apply(),</span>
<span class="w">  </span><span class="c1">// 2. User should lock the mutex during Node::apply(), this is to ensure Node</span>
<span class="w">  </span><span class="c1">// that</span>
<span class="w">  </span><span class="c1">//    writing to the shared variable are not racing across threads (i.e.</span>
<span class="w">  </span><span class="c1">//    AccumulateGrad and custom C++ Autograd Node if writing to shared</span>
<span class="w">  </span><span class="c1">//    variables )</span>
<span class="w">  </span><span class="c1">// 3. item 2 and item 3 should work together so that when we release saved</span>
<span class="w">  </span><span class="c1">// variables</span>
<span class="w">  </span><span class="c1">//    from one thread, no other threads can call Node::apply(), this ensures</span>
<span class="w">  </span><span class="c1">//    the variable references from other threads aren&#39;t dangling.</span>
<span class="w">  </span><span class="c1">// 4. if the Node don&#39;t release any variables and no shared data read/write in</span>
<span class="w">  </span><span class="c1">// the Node</span>
<span class="w">  </span><span class="c1">//    i.e. purely functional, user don&#39;t need to lock the mutex</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">// This way we could protect the thread safety on Autograd Node, but we could</span>
<span class="w">  </span><span class="c1">// still not protect the thread safety on Node pre/post C++ hooks (python</span>
<span class="w">  </span><span class="c1">// hooks are automatically thread safe), we rely on the user to write thread</span>
<span class="w">  </span><span class="c1">// safe C++ hooks if they want the hook to be correctly applied in</span>
<span class="w">  </span><span class="c1">// multithreading environment.</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">mutex</span><span class="w"> </span><span class="n">mutex_</span><span class="p">;</span>

<span class="w">  </span><span class="n">edge_list</span><span class="w"> </span><span class="n">next_edges_</span><span class="p">;</span>
<span class="w">  </span><span class="n">PyObject</span><span class="o">*</span><span class="w"> </span><span class="n">pyobj_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span><span class="w"> </span><span class="c1">// weak reference</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">AnomalyMetadata</span><span class="o">&gt;</span><span class="w"> </span><span class="n">anomaly_metadata_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// NOTE [Hooks ordering]</span>
<span class="w">  </span><span class="c1">// We have 3 separate fields for pre hooks registered to the autograd nodes</span>
<span class="w">  </span><span class="c1">// because the conditions under which they execute are different, and we</span>
<span class="w">  </span><span class="c1">// want more fine-grained control over the order in which different types</span>
<span class="w">  </span><span class="c1">// of hooks are executed.</span>
<span class="w">  </span><span class="c1">// - pre_hooks  are only executed when the node itself is executed</span>
<span class="w">  </span><span class="c1">// - tensor_pre_hook is executed as long as the engine traverses over it</span>
<span class="w">  </span><span class="c1">//   even if that node won&#39;t be executed.</span>
<span class="w">  </span><span class="c1">// - retains_grad_hook are like tensor_pre_hooks except they are always</span>
<span class="w">  </span><span class="c1">//   ordered after all other tensor pre hooks</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">FunctionPreHook</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">pre_hooks_</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">FunctionPreHook</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">tensor_pre_hooks_</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">unordered_map</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">FunctionPreHook</span><span class="o">&gt;&gt;</span>
<span class="w">      </span><span class="n">retains_grad_hooks_</span><span class="p">;</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">FunctionPostHook</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">post_hooks_</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">SmallVector</span><span class="o">&lt;</span><span class="n">InputMetadata</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="o">&gt;</span><span class="w"> </span><span class="n">input_metadata_</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">struct</span><span class="w"> </span><span class="nc">TraceableFunction</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">Node</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">Node</span><span class="o">::</span><span class="n">Node</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">is_traceable</span><span class="p">()</span><span class="w"> </span><span class="k">final</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>

<span class="c1">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="c1">//                       Associated Free Nodes</span>
<span class="c1">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">detail</span><span class="w"> </span><span class="p">{</span>
<span class="c1">// Implementation of `collect_next_edges` (see below).</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">MakeNextFunctionList</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">IterArgs</span><span class="o">&lt;</span><span class="n">MakeNextFunctionList</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">edge_list</span><span class="w"> </span><span class="n">next_edges</span><span class="p">;</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">IterArgs</span><span class="o">&lt;</span><span class="n">MakeNextFunctionList</span><span class="o">&gt;::</span><span class="k">operator</span><span class="p">();</span>
<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="nf">operator</span><span class="p">()(</span><span class="k">const</span><span class="w"> </span><span class="n">Variable</span><span class="o">&amp;</span><span class="w"> </span><span class="n">variable</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">variable</span><span class="p">.</span><span class="n">defined</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">next_edges</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">impl</span><span class="o">::</span><span class="n">gradient_edge</span><span class="p">(</span><span class="n">variable</span><span class="p">));</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">next_edges</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="nf">operator</span><span class="p">()(</span><span class="k">const</span><span class="w"> </span><span class="n">Variable</span><span class="o">*</span><span class="w"> </span><span class="n">variable</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">operator</span><span class="p">()(</span><span class="o">*</span><span class="n">variable</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="nf">operator</span><span class="p">()(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">Variable</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">variable</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">variable</span><span class="p">.</span><span class="n">has_value</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">operator</span><span class="p">()(</span><span class="o">*</span><span class="n">variable</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">next_edges</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="c1">// namespace detail</span>

<span class="kr">inline</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">create_gradient_edge</span><span class="p">(</span>
<span class="w">    </span><span class="n">Variable</span><span class="o">&amp;</span><span class="w"> </span><span class="n">variable</span><span class="p">,</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">Node</span><span class="o">&gt;</span><span class="w"> </span><span class="n">function</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Copy before move.</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">input_nr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">function</span><span class="o">-&gt;</span><span class="n">add_input_metadata</span><span class="p">(</span><span class="n">variable</span><span class="p">);</span>
<span class="w">  </span><span class="n">impl</span><span class="o">::</span><span class="n">set_gradient_edge</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">function</span><span class="p">),</span><span class="w"> </span><span class="n">input_nr</span><span class="p">});</span>
<span class="p">}</span>

<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">any_variable_requires_grad</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">variable_list</span><span class="o">&amp;</span><span class="w"> </span><span class="n">variables</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">any_of</span><span class="p">(</span>
<span class="w">      </span><span class="n">variables</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">variables</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="w"> </span><span class="p">[](</span><span class="k">const</span><span class="w"> </span><span class="n">Variable</span><span class="o">&amp;</span><span class="w"> </span><span class="n">variable</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">variable</span><span class="p">.</span><span class="n">defined</span><span class="p">()</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">variable</span><span class="p">.</span><span class="n">requires_grad</span><span class="p">();</span>
<span class="w">      </span><span class="p">});</span>
<span class="p">}</span>

<span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="p">...</span><span class="w"> </span><span class="n">Variables</span><span class="o">&gt;</span>
<span class="n">edge_list</span><span class="w"> </span><span class="n">collect_next_edges</span><span class="p">(</span><span class="n">Variables</span><span class="o">&amp;&amp;</span><span class="p">...</span><span class="w"> </span><span class="n">variables</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">detail</span><span class="o">::</span><span class="n">MakeNextFunctionList</span><span class="w"> </span><span class="n">make</span><span class="p">;</span>
<span class="w">  </span><span class="n">make</span><span class="p">.</span><span class="n">apply</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">forward</span><span class="o">&lt;</span><span class="n">Variables</span><span class="o">&gt;</span><span class="p">(</span><span class="n">variables</span><span class="p">)...);</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">make</span><span class="p">.</span><span class="n">next_edges</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">struct</span><span class="w"> </span><span class="nc">TypeAndSize</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">TypeAndSize</span><span class="p">()</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span>
<span class="w">  </span><span class="cm">/* implicit */</span>
<span class="w">  </span><span class="n">TypeAndSize</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">t</span><span class="p">)</span>
<span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">sym_sizes</span><span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="n">sym_sizes</span><span class="p">().</span><span class="n">vec</span><span class="p">()),</span><span class="w"> </span><span class="n">options</span><span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="n">options</span><span class="p">())</span><span class="w"> </span><span class="p">{}</span>

<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">zeros</span><span class="p">();</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">sym_sizes</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="p">;</span>
<span class="p">};</span>

<span class="p">}</span><span class="w"> </span><span class="c1">// namespace torch::autograd</span>
</pre></div>
</div>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5"></span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="file_torch_csrc_autograd_function.h.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">File function.h</p>
      </div>
    </a>
    <a class="right-next"
       href="file_torch_csrc_api_include_torch_nn_functional.h.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">File functional.h</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="file_torch_csrc_autograd_function.h.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">File function.h</p>
      </div>
    </a>
    <a class="right-next"
       href="file_torch_csrc_api_include_torch_nn_functional.h.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">File functional.h</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
    <div class="tocsection sourcelink">
      <a href="../_sources/api/program_listing_file_torch_csrc_autograd_function.h.rst.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
      </a>
    </div>
</div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  

<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
      </div>

      <div class="col-md-4">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>




<footer class="site-footer">

  <div class="container footer-container">

    <div class="newsletter" id="newsletter">

      <p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>


      <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
      <script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>


      <p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a
          href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>

    </div>

    <div class="lf-grid">
      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook">
              <path fill="currentColor"
                d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" />
            </svg>
          </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X">
              <path fill="currentColor"
                d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" />
            </svg>
          </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube">
              <path fill="currentColor"
                d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" />
            </svg>
          </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn">
              <rect width="512" height="512" rx="0" fill="currentColor" />
              <circle fill="#000" cx="142" cy="138" r="37" />
              <path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198" />
              <path fill="#000"
                d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" />
            </svg>
          </a></li>
        <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack">
              <path fill="currentColor"
                d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z">
              </path>
            </svg>
          </a></li>
        <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat">
              <path fill="currentColor"
                d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z">
              </path>
              <path fill="currentColor"
                d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z">
              </path>
            </svg>
          </a></li>
      </ul>
    </div>
    
    <div class="privacy-policy">
      <div class="copyright">
      
        <p>
          &copy; PyTorch. Copyright  The Linux Foundation. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a
            href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a
            href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebooks Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
       Copyright PyTorch Contributors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Program Listing for File function.h",
       "headline": "Program Listing for File function.h",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/api/program_listing_file_torch_csrc_autograd_function.h.html",
       "articleBody": "Program Listing for File function.h# \u21b0 Return to documentation for file (torch/csrc/autograd/function.h) #pragma once #include \u003ctorch/csrc/autograd/anomaly_mode.h\u003e #include \u003ctorch/csrc/autograd/edge.h\u003e #include \u003ctorch/csrc/autograd/grad_mode.h\u003e #include \u003ctorch/csrc/autograd/graph_task.h\u003e #include \u003ctorch/csrc/autograd/input_metadata.h\u003e #include \u003ctorch/csrc/autograd/saved_variable.h\u003e #include \u003ctorch/csrc/autograd/variable.h\u003e #include \u003ctorch/csrc/utils/python_stub.h\u003e #include \u003ctorch/csrc/utils/variadic.h\u003e #include \u003cATen/SequenceNumber.h\u003e #include \u003cATen/core/Tensor.h\u003e #include \u003cATen/record_function.h\u003e #include \u003cc10/util/Exception.h\u003e #include \u003cc10/util/irange.h\u003e #include \u003calgorithm\u003e #include \u003ccstdint\u003e #include \u003cinitializer_list\u003e #include \u003cmemory\u003e #include \u003cstring\u003e #include \u003cutility\u003e #include \u003cvector\u003e namespace torch::autograd { struct Edge; struct FunctionPostHook; struct FunctionPreHook; using tensor_list = std::vector\u003cat::Tensor\u003e; using variable_list = std::vector\u003cVariable\u003e; using edge_list = std::vector\u003cEdge\u003e; using saved_variable_list = std::vector\u003cSavedVariable\u003e; using ivalue_list = std::vector\u003cc10::IValue\u003e; using functional_apply_t = std::function\u003c variable_list(const variable_list\u0026, const std::vector\u003cc10::IValue\u003e\u0026)\u003e; using IndexRange = std::pair\u003csize_t, size_t\u003e; using torch::dynamo::autograd::CompiledNodeArgs; using torch::dynamo::autograd::PackedArgs; using torch::dynamo::autograd::SwapSavedVariables; // Custom deleter to prevent stack overflows. TORCH_API void deleteNode(Node* function); // Guard that sets and restores the evaluating node class NodeGuard { public: explicit NodeGuard(std::shared_ptr\u003cNode\u003e node); ~NodeGuard(); private: std::shared_ptr\u003cNode\u003e last_evaluating_node_; }; // Return the Node currently being evaluated (if any) // This is only set during the backward pass while a Node is being // executed. TORCH_API std::shared_ptr\u003cNode\u003e get_current_node(); //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ // Node //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ // A `Node` is an abstract class that represents an operation taking zero // or more input `Variable`s and producing zero or more output `Variable`s. All // functions in PyTorch\u0027s autograd machinery derive from this class and // override its `apply` method. Instances of such subclasses will then be // invocable via the call operator. // // Nodes in the Autograd Graph //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ // When viewing the autograd system as a graph, `Node`s are the vertices or // nodes, connected to each other via (directed) `Edge`s, which themselves are // represented via (`Node`, input_nr) pairs. `Variable`s are the outputs to // and inputs of `Node`s, and travel between these edges during execution // of the graph. When two or more `Edge`s (from different sources) point at the // same input to a `Node`, the values produced along all of these edges are // implicitly summed prior to being forwarded to the target `Node`. // // Hierarchy //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ // Subclasses usually represent differentiable functions as well as their // gradient operators. Note, however, that due to the very general definition // of a `Node` taking *zero* or more inputs and producing *zero* or more // outputs, uses of `Node`s are flexible and extend beyond purely // mathematical operations. For example, the `AccumulateGrad` function is a // *sink*: it takes one input, but produces no outputs, instead accumulating // the input as a side effect. At the other extreme, the `GraphRoot` function // receives no inputs from other functions, but produces multiple outputs. // // Interface //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ // The most important method on `Node` is the call operator, which takes in // a list of variables and produces a list of variables. The precise size of // these lists can be determined with `num_inputs()` and `num_outputs()`. // `Node`s are stitched together via their `next_edge` interface, which let // you manipulate the set of outgoing edges of a `Node`. You can add an // edge with `add_next_edge()`, retrieve an edge with `next_edge(index)` and // iterate over them via the `next_edges()` method. Other methods exist for // integration with the JIT and other parts of PyTorch. Every `Node` has a // *sequence number* that increases monotonically in the order of `Node` // construction. It can be retrieved via the `sequence_nr()` method. Note that // this sequence number is *thread local*. This means that when `Node`s // `A`, `B` and `C` are created consecutively in the same thread, their // sequence numbers will be ordered `A` \u003c `B` \u003c `C`. If, however, `A` and `B` // are created in one thread and `C` is created in a new thread, there are *no // guarantees* w.r.t. the ordering of `C` relative to `A` or `B`. // See NOTE [ Sequence Number] for more details on the usages of sequence // number. //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ struct TORCH_API Node : std::enable_shared_from_this\u003cNode\u003e { public: explicit Node(uint64_t sequence_nr, edge_list\u0026\u0026 next_edges = edge_list()) : sequence_nr_(sequence_nr), next_edges_(std::move(next_edges)) { for (const Edge\u0026 edge : next_edges_) { update_topological_nr(edge); } if (AnomalyMode::is_enabled()) { metadata()-\u003estore_stack(); // If anomaly mode is enabled and graph is constructed, then assign the // currently evaluating node as the parent of this node. // A parent is a Node where this Node is created. // We are tracking the parents to track multiple backward operations. assign_parent(); } // Store the thread_id of the forward operator. // See NOTE [ Sequence Numbers ] thread_id_ = at::RecordFunction::currentThreadId(); } explicit Node(edge_list\u0026\u0026 next_edges = edge_list()) : Node( /*sequence_nr=*/at::sequence_number::get_and_increment(), std::move(next_edges)) {} Node(const Node\u0026 other) = delete; Node(Node\u0026\u0026 other) = delete; Node\u0026 operator=(const Node\u0026 other) = delete; Node\u0026 operator=(Node\u0026\u0026 other) = delete; virtual ~Node() = default; std::shared_ptr\u003cNode\u003e getptr() { return shared_from_this(); } variable_list operator()(variable_list\u0026\u0026 inputs) { // In the first iteration of named tensors, autograd ignores names and // operates on unnamed tensors. In the long term, autograd should // probably operate with names. at::NoNamesGuard no_names_guard; #ifdef USE_ROCM // Keep track of backward pass for rocblas. at::ROCmBackwardPassGuard in_backward; #endif auto step_callbacks = at::getStepCallbacksUnlessEmpty(at::RecordScope::BACKWARD_FUNCTION); if (C10_UNLIKELY(step_callbacks.has_value())) { at::RecordFunction guard(std::move(*step_callbacks)); // Using sequence number and thread id to correlate with // the forward pass function guard.setForwardThreadId(thread_id_); if (guard.needsInputs()) { std::vector\u003cc10::IValue\u003e inputs_vec(inputs.begin(), inputs.end()); guard.before( name(), c10::ArrayRef\u003cconst c10::IValue\u003e( inputs_vec.data(), inputs_vec.size()), static_cast\u003cint64_t\u003e(sequence_nr())); } else { guard.before(name(), static_cast\u003cint64_t\u003e(sequence_nr())); } return apply(std::move(inputs)); } else { return apply(std::move(inputs)); } } // Graph Connectivity API //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ // Inputs. NOTE: inputs of the grad_fn correspond to Tensor outputs of the // forward function. // Marker for expected undefined input struct undefined_input {}; uint32_t add_input_metadata( const at::TensorOptions\u0026 options, c10::SymIntArrayRef shape, bool is_tensor_subclass, bool is_nested, std::optional\u003cat::ScalarType\u003e grad_dtype) noexcept { uint32_t input_nr = input_metadata_.size(); auto meta_shape = MetadataShape{std::in_place_type\u003cSymIntSmallVec\u003e, shape}; input_metadata_.emplace_back( options, meta_shape, is_tensor_subclass, is_nested, grad_dtype); return input_nr; } uint32_t add_input_metadata(const at::Tensor\u0026 t) noexcept { uint32_t input_nr = input_metadata_.size(); input_metadata_.emplace_back(t); return input_nr; } uint32_t add_input_metadata(undefined_input u) noexcept { uint32_t input_nr = input_metadata_.size(); input_metadata_.emplace_back(); return input_nr; } uint32_t num_inputs() const noexcept { return input_metadata_.size(); } const InputMetadata\u0026 input_metadata(size_t index) const { return input_metadata_[index]; } // Danger: not thread safe, caller must protect with lock InputMetadata\u0026 mutable_input_metadata(size_t index) { return input_metadata_[index]; } std::optional\u003cc10::Stream\u003e stream() { auto opt_device_type = at::getAccelerator(); if (!opt_device_type.has_value()) { return std::nullopt; } for (const auto\u0026 metadata : input_metadata_) { if (metadata.device().type() == opt_device_type.value()) return metadata.stream(); } return std::nullopt; } // Used by the engine to determine what device thread to run on at::Device device() { // Since we pick the first non-CPU tensor, this won\u0027t work with // mixed device-type operations (e.g., an op that is both CUDA // and XLA). This is *incredibly* unlikely, so we don\u0027t worry // about it. for (const auto\u0026 metadata : input_metadata_) { auto device = metadata.device(); if (device.type() != at::kCPU) { return device; } } // Only report to the CPU thread if there really were no tensors // from other devices. return at::kCPU; } void clear_input_metadata() { input_metadata_.clear(); } // Outputs (\"Next Edges\") void update_topological_nr(const Edge\u0026 edge) { TORCH_INTERNAL_ASSERT( !has_parent_, \"Cannot update a node\u0027s topological_nr after it already has a parent.\" \" If we allow this, we can no longer guarantee that a parent\u0027s\" \" topo_nr is always greater than those of all its children\") Node* node = edge.function.get(); if (node) { auto topo_nr = node-\u003etopological_nr(); if (topological_nr_ \u003c= topo_nr) { topological_nr_ = topo_nr + 1; } } } void set_next_edge(size_t index, Edge edge) { update_topological_nr(edge); next_edges_[index] = std::move(edge); } void add_next_edge(Edge edge) { update_topological_nr(edge); next_edges_.emplace_back(std::move(edge)); } void set_next_edges(edge_list\u0026\u0026 next_edges) { next_edges_ = std::move(next_edges); for (const auto\u0026 next_edge : next_edges_) { update_topological_nr(next_edge); } } const Edge\u0026 next_edge(size_t index) const noexcept { return next_edges_[index]; } const edge_list\u0026 next_edges() const noexcept { return next_edges_; } edge_list\u0026 next_edges() noexcept { return next_edges_; } uint32_t num_outputs() const noexcept { return next_edges_.size(); } // Miscellaneous Methods //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ uint64_t sequence_nr() const noexcept { return sequence_nr_; } void set_sequence_nr(uint64_t sequence_nr) { sequence_nr_ = sequence_nr; } // NOTE [ Topological Number ] // // topological_nr is used to prune branches in the DAG during autograd // discovery as maintaining topological_nr helps us check in O(1) if there // does NOT exist a directed path between two nodes. // // The topological order number of this `Node` representing the length of the // longest possible path from this Node to any leaf node. If you are leaf // node, aka AccumulateGrad, this will be zero. This value has the property // that For every pair of nodes X, Y in G, existence of a directed path from X // to Y implies topo_nr(X) \u003e topo_nr(Y). The converse is not true, however, so // we cannot prove existence of a path from X to Y, only non-existence. // // One assumption we make when using topo_nr is that once a node // has been used, i.e., has a parent node, its own topo_nr does not change // we have added some checks with the `has_parent_` field to enforce this. // // What NOT to do: // // 1) 2 -\u003e 1 -\u003e 0 In this diagram we label nodes with their // topo_nr. // 2 -\u003e 1 -\u003e 0 We have two simple graphs that can each // arise from // `t.exp().exp()`, for example. // 2) 2 -\u003e 1 -\u003e 0 // / // 2 -\u003e 1 -\u003e 0 We add 2 as a next edge to 1 even though 1 // already // has a parent. // 3) 2 -\u003e 1 -\u003e 0 // / // 2 -\u003e 3 -\u003e 0 2 \u003c 3, yet there exists a path from 2 to 3! // uint64_t topological_nr() const noexcept { has_parent_ = true; return topological_nr_; } // assigning a node as a parent to this node void assign_parent(); uint64_t thread_id() const noexcept { return thread_id_; } virtual std::string name() const; bool should_compute_output(size_t output_edge_index) const { TORCH_CHECK(output_edge_index \u003c num_outputs(), \"Index out of range\"); return next_edges_[output_edge_index].is_valid(); } bool should_compute_output(std::initializer_list\u003cIndexRange\u003e idxs) const { return std::any_of(idxs.begin(), idxs.end(), [this](IndexRange range) { for (const auto i : c10::irange(range.first, range.second)) { if (should_compute_output(i)) return true; } return false; }); } bool task_should_compute_output(size_t output_edge_index) const { TORCH_CHECK(output_edge_index \u003c num_outputs(), \"Index out of range\"); const auto\u0026 next = next_edges_[output_edge_index]; if (next.is_valid()) { const auto exec_info = get_current_graph_task_exec_info(); if (exec_info \u0026\u0026 !exec_info-\u003eempty()) { auto it = exec_info-\u003efind(next.function.get()); if (it == exec_info-\u003eend() || !it-\u003esecond.should_execute()) { return false; // this edge is not needed for the current graph_task } } return true; } return false; } bool task_should_compute_output( std::initializer_list\u003cIndexRange\u003e idxs) const { return std::any_of(idxs.begin(), idxs.end(), [this](IndexRange range) { for (const auto i : c10::irange(range.first, range.second)) { if (task_should_compute_output(i)) return true; } return false; }); } PyObject* pyobj() const noexcept { return pyobj_; } void set_pyobj(PyObject* pyobj) noexcept { pyobj_ = pyobj; } AnomalyMetadata* metadata() noexcept; // Hook API //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ uintptr_t add_post_hook(std::unique_ptr\u003cFunctionPostHook\u003e\u0026\u0026 post_hook) { post_hooks_.emplace_back(std::move(post_hook)); // Use the raw pointer as the unique key to identify this hook. This key // can then be used in del_post_hook(key) to remove this hook. return reinterpret_cast\u003cstd::uintptr_t\u003e(post_hooks_.back().get()); } const std::vector\u003cstd::unique_ptr\u003cFunctionPostHook\u003e\u003e\u0026 post_hooks() const noexcept { return post_hooks_; } // delete a post hook matching the key bool del_post_hook(const uintptr_t\u0026 key) { for (auto it = post_hooks_.begin(); it != post_hooks_.end(); ++it) { if (key == reinterpret_cast\u003cstd::uintptr_t\u003e(it-\u003eget())) { post_hooks_.erase(it); return true; } } return false; } std::vector\u003cstd::unique_ptr\u003cFunctionPostHook\u003e\u003e\u0026 post_hooks() noexcept { return post_hooks_; } void add_pre_hook(std::unique_ptr\u003cFunctionPreHook\u003e\u0026\u0026 pre_hook) { pre_hooks_.emplace_back(std::move(pre_hook)); } void add_tensor_pre_hook(std::unique_ptr\u003cFunctionPreHook\u003e\u0026\u0026 pre_hook) { tensor_pre_hooks_.emplace_back(std::move(pre_hook)); } void add_retains_grad_hook( std::unique_ptr\u003cFunctionPreHook\u003e\u0026\u0026 pre_hook, size_t output_idx) { retains_grad_hooks_[output_idx] = std::move(pre_hook); } std::unique_ptr\u003cFunctionPreHook\u003e pop_retains_grad_hook(size_t output_idx) { auto ret = std::move(retains_grad_hooks_[output_idx]); retains_grad_hooks_.erase(output_idx); return ret; } const std::vector\u003cstd::unique_ptr\u003cFunctionPreHook\u003e\u003e\u0026 pre_hooks() const noexcept { return pre_hooks_; } std::vector\u003cstd::unique_ptr\u003cFunctionPreHook\u003e\u003e\u0026 pre_hooks() noexcept { return pre_hooks_; } virtual std::vector\u003cstd::unique_ptr\u003cFunctionPreHook\u003e\u003e\u0026 tensor_pre_hooks() noexcept { return tensor_pre_hooks_; } virtual std::unique_ptr\u003cPostAccumulateGradHook\u003e\u0026 tensor_post_acc_grad_hooks() const noexcept { static std::unique_ptr\u003cPostAccumulateGradHook\u003e empty = nullptr; return empty; } std::unordered_map\u003csize_t, std::unique_ptr\u003cFunctionPreHook\u003e\u003e\u0026 retains_grad_hooks() noexcept { return retains_grad_hooks_; } // Customization Points for Subclasses //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ virtual void release_variables() {} virtual void will_release_variables() {} virtual bool is_traceable() { return false; } virtual bool passes_state_transparently() { return false; } // see [Note: Compiled Autograd] // Used by compiled autograd to // 1) Extract tensors/symint args // 2) Collect node information for specialization and caching // Implementations in subclasses should call args.collect() with all node // attrs. These functions are only called during backward. virtual void compiled_args(CompiledNodeArgs\u0026 args) const { TORCH_CHECK_NOT_IMPLEMENTED( false, std::string(\"compiled_args not implemented: \") + name()); } // Used by compiled autograd to call apply() with different saved tensors // Implementations should call saved.before() on all attrs, then apply(), then // saved.after() on all attrs in the same order. virtual variable_list apply_with_saved( const variable_list\u0026 inputs, SwapSavedVariables\u0026 saved) { TORCH_CHECK_NOT_IMPLEMENTED( false, std::string(\"apply_with_saved not implemented: \") + name()); } // If this node is the AOTBackward node produced by torch.compile. // Compiled Autograd special-cases on this information. virtual bool is_aot_backward() const { return false; } protected: virtual variable_list apply(variable_list\u0026\u0026 inputs) = 0; variable_list traced_apply(variable_list inputs); // Sequence number used to correlate backward nodes with forward ops in the // profiler and provide determinism in the engine. // NOLINTNEXTLINE(cppcoreguidelines-avoid-const-or-ref-data-members) uint64_t sequence_nr_; // See NOTE [ Topological Number ] uint64_t topological_nr_ = 0; // Tracks whether this node has been added as the next_edge of another node // via set_next_edge(s), which always calls topological_nr() of all its // children See NOTE [ Topological Number ] for why we need this. mutable bool has_parent_ = false; // Id of the thread that created the instance uint64_t thread_id_ = 0; // Note [Thread Safety on Autograd Node] // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ // Autograd Engine let the owning thread which calls Engine::execute to drive // the GraphTask execution, there might be cases that part of the GraphTask is // shared across different `backward()` or `grad()` calls, i.e. fork new // threads in the middle of the forward and call `backward()` separately from // different threads. We need to protect the thread safety on NodeTask to // prevent data racing on shared variables read/write. // // NB: This is only needed for Autograd Nodes that runs on CPU, technically // \"CUDA\", \"XLA\" nodes don\u0027t need locking because device threads are always // single threaded. // // Here we add a thread mutex to help protect the Node\u0027s thread safety, so // that different threads cannot race the shared data when executing the same // NodeTask from multiple CPU threads. It IS the user/developer responsibility // to take advantage of this mutex to protect the thread safety of their // autograd Node. The general strategy of thread safety on autograd Node: // // 1. User should lock the mutex during Node::release_variables() if the Node // needs // to release the variables on the fly, this serve the purpose that when we // release saved_variables from one thread, no other threads can release // the saved variables concurrently. call the Node::apply(), // 2. User should lock the mutex during Node::apply(), this is to ensure Node // that // writing to the shared variable are not racing across threads (i.e. // AccumulateGrad and custom C++ Autograd Node if writing to shared // variables ) // 3. item 2 and item 3 should work together so that when we release saved // variables // from one thread, no other threads can call Node::apply(), this ensures // the variable references from other threads aren\u0027t dangling. // 4. if the Node don\u0027t release any variables and no shared data read/write in // the Node // i.e. purely functional, user don\u0027t need to lock the mutex // // This way we could protect the thread safety on Autograd Node, but we could // still not protect the thread safety on Node pre/post C++ hooks (python // hooks are automatically thread safe), we rely on the user to write thread // safe C++ hooks if they want the hook to be correctly applied in // multithreading environment. std::mutex mutex_; edge_list next_edges_; PyObject* pyobj_ = nullptr; // weak reference std::unique_ptr\u003cAnomalyMetadata\u003e anomaly_metadata_ = nullptr; // NOTE [Hooks ordering] // We have 3 separate fields for pre hooks registered to the autograd nodes // because the conditions under which they execute are different, and we // want more fine-grained control over the order in which different types // of hooks are executed. // - pre_hooks are only executed when the node itself is executed // - tensor_pre_hook is executed as long as the engine traverses over it // even if that node won\u0027t be executed. // - retains_grad_hook are like tensor_pre_hooks except they are always // ordered after all other tensor pre hooks std::vector\u003cstd::unique_ptr\u003cFunctionPreHook\u003e\u003e pre_hooks_; std::vector\u003cstd::unique_ptr\u003cFunctionPreHook\u003e\u003e tensor_pre_hooks_; std::unordered_map\u003csize_t, std::unique_ptr\u003cFunctionPreHook\u003e\u003e retains_grad_hooks_; std::vector\u003cstd::unique_ptr\u003cFunctionPostHook\u003e\u003e post_hooks_; at::SmallVector\u003cInputMetadata, 2\u003e input_metadata_; }; struct TraceableFunction : public Node { using Node::Node; bool is_traceable() final { return true; } }; //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ // Associated Free Nodes //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ namespace detail { // Implementation of `collect_next_edges` (see below). struct MakeNextFunctionList : IterArgs\u003cMakeNextFunctionList\u003e { edge_list next_edges; using IterArgs\u003cMakeNextFunctionList\u003e::operator(); void operator()(const Variable\u0026 variable) { if (variable.defined()) { next_edges.emplace_back(impl::gradient_edge(variable)); } else { next_edges.emplace_back(); } } void operator()(const Variable* variable) { operator()(*variable); } void operator()(const std::optional\u003cVariable\u003e\u0026 variable) { if (variable.has_value()) { operator()(*variable); } else { next_edges.emplace_back(); } } }; } // namespace detail inline void create_gradient_edge( Variable\u0026 variable, std::shared_ptr\u003cNode\u003e function) { // Copy before move. const auto input_nr = function-\u003eadd_input_metadata(variable); impl::set_gradient_edge(variable, {std::move(function), input_nr}); } inline bool any_variable_requires_grad(const variable_list\u0026 variables) { return std::any_of( variables.begin(), variables.end(), [](const Variable\u0026 variable) { return variable.defined() \u0026\u0026 variable.requires_grad(); }); } template \u003ctypename... Variables\u003e edge_list collect_next_edges(Variables\u0026\u0026... variables) { detail::MakeNextFunctionList make; make.apply(std::forward\u003cVariables\u003e(variables)...); return std::move(make.next_edges); } struct TypeAndSize { TypeAndSize() = default; /* implicit */ TypeAndSize(const at::Tensor\u0026 t) : sym_sizes(t.sym_sizes().vec()), options(t.options()) {} at::Tensor zeros(); std::vector\u003cc10::SymInt\u003e sym_sizes; at::TensorOptions options; }; } // namespace torch::autograd",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/api/program_listing_file_torch_csrc_autograd_function.h.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>